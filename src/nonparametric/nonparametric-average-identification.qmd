--- 
description: " (Lecture Notes)"

open-graph:
    description: "  (Lecture Notes)"
---


# Identifying Average Effects for Stayers {#sec-nonparametric-avg-id}

::: {.callout-note appearance="simple" icon=false}

## Summary and Learning Outcomes

This section  

By the end of this section, you should be able to: 

- Explain  

:::

## A Finite Difference Perspective on Heterogeneity Bias

The previous section highlighted how heterogeneity bias prevents identification of causal marginal effects using cross-sectional averages. We now show how panel data structure, together with smoothness and stationarity assumptions, can overcome this issue.

To motivate our identification strategy for average marginal effects, it is helpful to recall the definition of a derivative. Recall that the derivative of a function $g$ is just the limit of a sequence of finite differences:
$$
	g'(x) = \lim\limits_{h\to 0}\dfrac{g(x+h)-g(x)}{h}.
$$

If we take $g(x)=\E[Y_{it}|X_{it}=x]$, the above finite difference is given by 
$$
\begin{aligned}
	& \dfrac{\E[Y_{it}|X_{it} = x+h] - \E[Y_{it} |X_{it}=x] }{h} \\
    & =  \dfrac{\E[\phi(x+h, A_i, U_{it})|X_{it}=x+h] - \E[\phi(x,  A_i, U_{it})|X_{it}=x] }{h}.
\end{aligned}
$$ {#eq-nonparametric-avg-FD-exp}
Notice that the conditioning sets on the two expectations are different. Consequently, the conditional distributions of $(A_i, U_{it})$ given $X_{it}$ are different between the two expectations. In other words, we cannot hold the distribution of  $(A_i, U_{it})$ fixed as we vary $x$ in $\E[Y_{it}|X_{it}]$. This violates the *ceteris paribus* logic required for interpreting $\partial_x \E[Y_{it} | X_{it} = x]$ as a causal effect, as mentioned in the previous section. 

The average marginal effect can itself be restated using a finite difference as
$$
\begin{aligned}
& \E[\partial_x\phi(x+h, A_i, U_{it}|\cdots] \\
&  = \E\left[\lim_{h\to 0}  \dfrac{ \phi(x+h, A_i, U_{it}) - \phi(x, A_i, U_{it})    }{h} \Bigg| \cdots \right].
\end{aligned}
$$  {#eq-nonparametric-avg-exp-fd-phi}
In this view, the failure of the naive approach of the previous section stems from the fact that we cannot interchange finite differences and expectations when using cross-sectional data in @eq-nonparametric-avg-FD-exp.




## Identifying Average Marginal Effects for Stayers



### Stationarity: Time as an Instrument

Panel data offers a natural way to address this failure of ceteris paribus reasoning. By comparing outcomes within the same unit, we can hold $A_i$ constant, isolating variation over time. 

At the same time, contrasting outcomes within the same unit necessarily means contrasting outcomes from different periods â€” and hence dealing with variation in $U_{it}$.

As it turns out, to handle such comparisons it is sufficient to assume that $U_{it}$ is conditionally stationary. Formally, we assume that the distribution $U_{i1}$ conditional on $(X_{i1}, X_{i2}, A_i)$ is equal to the conditional distribution of $U_{i2}$. Under this assumption, the distribution of $\phi(x, A_i, U_{it})$ does not depend on time $t$ any more given $(X_{i1}, X_{i2})$. Intuitively, one may think that time is randomly assigned to observations; an interpretation called "time as an instrument" [@Chernozhukov2013].

::: {.callout-note appearance="simple" icon=false}

The stationarity assumption actually imposes a time-invariance assumption on the structural function $\phi$. To see why, note that under this assumption $U_{it}$ cannot contain changing deterministic variables, including time $t$. In general, if $t$ is part of $U_{it}$, then the function could change arbitrarily between periods. There is effectively no value in panel data if such arbitrary changes are possible. The stationarity assumption rules out such situations. 

:::



### Two Key Analysis Steps

We base our panel data identification argument on the following expectations involving $\phi$
$$
	\E\left[ \dfrac{\phi(x+h, A_i, U_{i2}) - \phi(x, A_i, U_{i1})}{h}\Bigg|\cdots \right].
$$ {#eq-nonparametric-avg-key-exp}
Expectation ([-@eq-nonparametric-avg-key-exp]) reflects the idea sketched out above:

- The same $A_i$ appears in both $\phi$ terms.
- The $U_{it}$ terms change over time.

The latter point means that ([-@eq-nonparametric-avg-key-exp]) does not involve a genuine finite difference in contrast to @eq-nonparametric-avg-exp-fd-phi. As a consequence, there are two key pieces in our analysis:

- *Continuity*: showing that expectation ([-@eq-nonparametric-avg-key-exp]) does converge to the average marginal effect as $h\to 0$, despite not involving the "correct" finite difference. 
- *Identification*: showing that the limit of expectation ([-@eq-nonparametric-avg-key-exp]) is identified as $h\to 0$, at least for some subpopulation of interest. 

	 

### Identifying Moments of Finite Difference

We begin with the second piece. To identify the limit of expectation ([-@eq-nonparametric-avg-key-exp]) is identified as $h\to 0$, it is sufficient to identify of  ([-@eq-nonparametric-avg-key-exp]) for all $h>0$ in some neighborhood of 0. To do so, consider the population of units with $\curl{ X_{i1} = x, X_{i2}  = x+h}$. By model ([-@eq-nonparametric-model-full-nonsep-het-bias]), the outcomes of these units satisfy
$$
\begin{aligned}
	Y_{i2} & = \phi(x+h, A_i, U_{i2}),\\
	Y_{i1} & = \phi(x, A_i, U_{i1}).
\end{aligned}
$$
Accordingly,
$$
\begin{aligned}
	&	\E\left[\dfrac{Y_{i2}-Y_{i1}}{h}\Bigg|X_{i1} = x, X_{i2} = x+h \right] \\
	& = \E\left[\dfrac{\phi(x+h, A_i, U_{i2}) - \phi(x, A_i, U_{i1})}{h}\Bigg|X_{i1} = x, X_{i2} = x+h  \right].
\end{aligned}
$$
We conclude that ([-@eq-nonparametric-avg-key-exp]) is identified for all $h>0$ small enough,  provided that the joint density of $(X_{i1}, X_{i2})$ is positive in some neighborhood of $(x, x)$, 

This arguments also determines the population for which identification holds. The units with $\curl{X_{i1}=x, X_{i2}=x+h}$ for small $h>0$   are often call near-stayers or slow movers in the literature [e.g. @Sasaki2021]. We return to this topic below. 





### Continuity of Average Finite Difference

We now turn to the continuity piece. Establishing continuity requires some continuity assumptions on the relationship between $X_{it}$, $A_i$ and $U_{it}$. To motivate their form, we write out ([-@eq-nonparametric-avg-key-exp]) as an integral, similarly to how we proceeded in the previous section. To that end, let 

- $f_{A_i, U_{i1}, U_{i2}|X_{i1}, X_{i2}}(a, u_1, u_2|x_1, x_2)$ be the conditional density of $(A_i, U_{i1}, U_{i2})$ given $\curl{X_{i1} =x_1, X_{i2}=x_2}$;
- $f_{U_{i1}, U_{i2}|X_{i1}, X_{i2}, A_i}(u_1, u_2|x_1, x_2, a)$ be the conditional density of $(U_{i1}, U_{i2})$ given $\curl{X_{i1} =x_1, X_{i2}=x_2, A_i=a}$;
- $f_{A_i|X_{i1}, X_{i2}}(a|x_1, x_2)$ be the conditional density of $A_i$ given $\curl{X_{i1}=x_1, X_{i2}=x_2}$ 
- $f_{U_{it}|X_{i1}, X_{i2}, A_i}(u_1, u_2|x_1, x_2, a)$ be the conditional density of $U_{it}$ given $\curl{X_{i1} =x_1, X_{i2}=x_2, A_i=a}$.
- $f_{A_i, U_{it}|X_{i1}, X_{i2}}(u_1, u_2|x_1, x_2, a)$ be the conditional density of $(A_i, U_{it})$ given $\curl{X_{i1} =x_1, X_{i2}=x_2}$.

Observe that the latter two densities do not depend on $t$ by assumption of stationarity!

Throughout, we assume that the above densities are taken with respect to some overall dominating measure $\mu$ that does not depend on $(x_1, x_2)$.

::: {.callout-note appearance="simple" icon=false collapse=true}

## Regarding $\mu$

Intuitively, the assumption that $\mu$ does not depend on $(x_1, x_2)$ means that the type of distribution of $(A_i, U_{it})$ does not depend with $(x_1, x_2)$. In the simplest case, imagine that $A_i$ and $U_{it}$ are just random scalars. The assumption states that the following two statements cannot be true at the same time: 

- For some $(x_1, x_2)$ there is only a finite number of possible values of $(A_i, U_{it})$ (with $\mu$ being the counting measure).
- For some $(x_1, x_2)$  there is a continuum of possible values of $(A_i, U_{it})$ with no atoms (with $\mu$ being the Lebesgue measure).

:::

With this notation, we can represent ([-@eq-nonparametric-avg-key-exp]) as 
$$
\begin{aligned}
	&	\E\left[\dfrac{\phi(x+h, A_i, U_{i2}) - \phi(x, A_i, U_{i1})}{h}\Bigg|X_{i1} = x, X_{i2} = x+h  \right]\\
    %
	& = \int \left[\phi(x+h, a, u_2) - \phi(x, a, u_1) \right] \\
	& \hspace{2cm}\times f_{A_i, U_{i1}, U_{i2}|X_{i1}, X_{i2}}(a, u_1, u_2|x,x+h) \mu(da, du_1, du_2)\\
    %
	& = \int \left[\phi(x+h, a, u_2) - \phi(x, a, u_1) \right]
	\\
	& \hspace{2cm}\times   f_{U_{i1}, U_{i2}|X_{i1}, X_{i2}, A_i}(u_1, u_2|x, x+h, a)
    	\\
	& \hspace{2cm}\times f_{A_i|X_{i1}, X_{i2}}(a|x, x+h) \mu(da, du_1, du_2)\\
    %
    	& = \int \left[\phi(x+h, a, u_2) - \phi(x, a, u_1) \right]
	\\
	& \hspace{2cm}\times   f_{U_{i1}, U_{i2}|X_{i1}, X_{i2}, A_i}(u_1, u_2|x, x+h, a)
    	\\
	& \hspace{2cm}\times f_{A_i|X_{i1}, X_{i2}}(a|x, x+h) \mu(da, du_1, du_2)
\end{aligned}
$$
Now we make three key observations:

1. We can split the integral into two integrals: one involving $\phi(x+h, a, u_2)$ and one involving $\phi(x, a, u_1)$. 
2. $\phi(x+h, a, u_2)$ does not depend on $u_1$, and so $u_{1}$ is just integrated out:
$$
\begin{aligned}
 & \int \phi(x+h, a, u_2)  f_{A_i|X_{i1}, X_{i2}}(a|x, x+h)
	\\
	& \hspace{2cm}\times   f_{U_{i1}, U_{i2}|X_{i1}, X_{i2}, A_i}(u_1, u_2|x, x+h, a) \mu(da, du_1, du_2)
    	\\
& = \int  \phi(x+h, a, u_2) f_{A_i|X_{i1}, X_{i2}}(a|x, x+h)
	\\
	& \hspace{2cm}\times   f_{U_{i2}|X_{i1}, X_{i2}, A_i}(u_2|x, x+h, a) \mu(da, du_2).
\end{aligned}
$$
3. The conditional density of $U_{i2}$ is equal to the time-invariant density $f_{U_{it}|X_{i1}, X_{i2}, A_i}$: 
$$
\begin{aligned}
& = \int  \phi(x+h, a, u_2) f_{A_i|X_{i1}, X_{i2}}(a|x, x+h)
	\\
	& \hspace{2cm}\times   f_{U_{i2}|X_{i1}, X_{i2}, A_i}(u_2|x, x+h, a) \mu(da, du_2)\\
& = \int  \phi(x+h, a, u) f_{A_i|X_{i1}, X_{i2}}(a|x, x+h)
	\\
	& \hspace{2cm}\times   f_{U_{it}|X_{i1}, X_{i2}, A_i}(u|x, x+h, a) \mu(da, du).
\end{aligned}
$$
4. A symmetric argument applies to the integral with $\phi(x, a, u_1)$.

We cinclude that we can represent ([-@eq-nonparametric-avg-key-exp]) as 
$$
\begin{aligned}
&	\E\left[\dfrac{\phi(x+h, A_i, U_{i2}) - \phi(x, A_i, U_{i1})}{h}\Bigg|X_{i1} = x, X_{i2} = x+h  \right]\\
& = \int \left[ \phi(x+h, a, u)  - \phi(x, a, u) \right]f_{A_i, U_{it}|X_{i1}, X_{i2}, A_i}(a|x, u, x+h) \mu(da, du) 
\end{aligned}
$$
In the second to last equality, we use the stationarity of $u_{it}$.


### Combined Results


### Interpretation



## Regarding the Identified Population

### Are Stayers Interesting? 


### Lack of Identification for Other Populations 

basically as far as thins go without more assumptions 

Outside of stayers no identification for counterfactuals in this models, see counterexamples constructed by @Cooprider2022.