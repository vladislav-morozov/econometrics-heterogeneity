[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Econometrics with Unobserved Heterogeneity",
    "section": "",
    "text": "Course Information",
    "crumbs": [
      "Course Information"
    ]
  },
  {
    "objectID": "index.html#course-information",
    "href": "index.html#course-information",
    "title": "Econometrics with Unobserved Heterogeneity",
    "section": "",
    "text": "Short Description\nUnobserved heterogeneity is pervasive in economics, driven by heterogeneous parameters and treatment effects, unobserved characteristics of agents, missing variables, etc. This class introduces methods for estimating parameters of interest in settings with such unobserved heterogeneity.\nThe course is structured into three main parts:\n\nLinear models with heterogeneous coefficients\nNonparametric models with unobserved heterogeneity\nQuantile and distributional treatment effects and quantile and distributional regression methods.\n\nThis class focuses on observational cross-sectional and panel data settings.\nInstructor: Vladislav Morozov \nLevel: Second-year Master’s and PhD students; accessible to sufficiently prepared upper-level undergraduate students \n\n\nCourse Materials\nTextbook: None. This course is based on lecture notes and background articles, which are listed in the references.\nRecommended Readings: Please see the bibliography for a detailed reading list.\n\n\nAbout These Notes\nThese lectures notes are based on a topics course I delivered at the University of Bonn. They are currently being uploaded in blocks as I organize and transform my notes. These notes are a work in progress. If you find any typos or have suggestions, please open an issue on GitHub using the link on the right!\nCurrent version (March 20, 2025): Includes material on average effects in linear models with heterogeneous coefficients.\n\n\nLearning Outcomes\nBy the end of this course, students will be able to:\n\nIdentify and explain different sources of unobserved heterogeneity in economic data.\nApply econometric methods, such as heterogeneous coefficient models and quantile regression, to account for unobserved heterogeneity.\nEvaluate the trade-offs and assumptions underlying different modeling approaches in empirical research.\n\n\n\nSyllabus\nBlock 0: Introduction to Unobserved Heterogeneity\n\nDefinition and a brief classification\nExamples in applied econometrics\nOverview of key methodological challenges\n\nBlock 1: Linear Models with Heterogeneous Coefficients\n\nLinear models and their applicability\n\nHeterogeneity in linear models\n\nAverage effects:\n\nIssues with the within estimator under heterogeneity\n\nInterlude: Dynamic panels with random intercepts\n\nIssues with dynamic panel IV estimators under heterogeneity\n\nRobust estimation with the mean group estimator\n\n\nVariance of coefficients\n\nDistribution of coefficients:\n\nA primer on deconvolution\n\nIdentification of the distribution\n\nEstimation with discrete covariates\n\n\nBlock 2: Nonparametric Models with Unobserved Heterogeneity\n\nA partial classification of nonparametric models with unobserved heterogeneity\n\nIntroduction to nonseparable models\n\nHeterogeneity bias and issues with identification in cross-sectional settings\n\nIdentification and estimation of average marginal effects in fully nonseparable models with panel data:\n\nIdentification for stayers under strong stationarity\n\nExtending identification results beyond stayers\n\nAccommodating changes in the structural function\n\n\nVariance of marginal effects in nonseparable models\n\nBlock 3: Quantile and Distribution Treatment Effects:\n\nBackground: Quantiles and their properties\n\nCausal framework: Quantile and distributional treatment effects and their interpretation\n\nIdentification of QTEs and DTEs under unconfoundedness\n\nMethods:\n\nQuantile regression:\n\nGeneral formulation\n\nWhen is quantile regression correctly specified?\n\nQuantile crossing and rearrangement techniques\n\n\nDistribution regression:\n\nGeneral formulation\n\nRearrangement for distribution regression\n\n\n\nEstimation of QTEs and DTEs\n\nWhat can quantile regressions tell us about nonseparable models?",
    "crumbs": [
      "Course Information"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Unobserved Heterogeneity\nIn economics, business, and other social sciences, no two individuals, firms, or countries are truly identical. Even when we observe the same covariates, hidden differences — such as preferences, productivity, or measurement errors — can lead to vastly different outcomes. These unobserved factors complicate empirical analysis and pose a fundamental challenge to statistical inference: how can we estimate policy-relevant parameters when key determinants of behavior remain hidden? This challenge, known as unobserved heterogeneity, is central to empirical research and the focus of this course.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#unobserved-heterogeneity",
    "href": "intro.html#unobserved-heterogeneity",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1.1 Types of Unobserved Heterogeneity\nBy unobserved heterogeneity, we will understand differences across individuals, firms, or other economic units that are not captured in the available data but still influence outcomes. These differences can arise from various sources, including:\n\nOmitted explanatory variables and “fundamental” characteristics of agents.\n\nExample: Consumer demand depends on both income and prices, but if price data is missing, it becomes an unobserved factor influencing demand.\nExample: Differences in consumer preferences shape demand, yet preferences are typically unobservable.\n\nDifferences in responses to treatments: treatment effect heterogeneity, heterogeneous coefficients, and differences in functional forms across individuals and groups.\n\nExample: A job training program may benefit some individuals more than others, meaning treatment effects vary across people.\n\nMeasurement error:\n\nExample: Standardized test scores are often used to proxy intelligence, but they are imperfect measurements of the true intelligence.\n\n\n\n\n1.1.2 Consequences of Ignoring Unobserved Heterogeneity\nUnobserved heterogeneity is particularly problematic in observational data, where individuals or firms can self-select into treatments or economic decisions. The agents make this decisions based on all the information available to them, but not all important variables get recorded in datasets. As a consequence, there exist hidden factors that confound the relationship between the explanatory variables and the outcomes. In contrast, in randomized experiments, treatments are assigned independently of the characteristics of agents (possibly conditionally). The following graphs schematically illustrate the point:\n\n\n\n\n\n\n\n\n\n\n\n\nCausalGraph\n\n\n\nA\n\nUnobserved\n\n\n\nC\n\nCovariates\n\n\n\nA-&gt;C\n\n\n\n\n\nB\n\nObserved\n\n\n\nB-&gt;C\n\n\n\n\n\n\n Experimental data: no confounding. \n\n\n\n\n\n\n\n\n\n\nCausalGraph\n\n\n\nA\n\nUnobserved\n\n\n\nB\n\nObserved\n\n\n\nA-&gt;B\n\n\n\n\nC\n\nCovariates\n\n\n\nA-&gt;C\n\n\n\n\n\nB-&gt;C\n\n\n\n\n\n\n Observational data: confounding \n\n\n\n\n\nAs a consequence, ignoring unobserved heterogeneity can lead to misleading statistical conclusions. Confounding manifests even in simple linear regression, with some examples including:\n\nOmitted variable bias: if an important explanatory variable is missing and correlated with observed covariates, coefficient estimates will be biased and inconsistent.\nAttenuation bias: When covariates suffer from measurement error, estimated effects tend to be systematically biased toward zero.\n\nThe issue becomes even more challenging in nonlinear models, where often even the direction of the bias cannot be predicted (e.g. Stefanski and Carroll 1985).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#this-course",
    "href": "intro.html#this-course",
    "title": "1  Introduction",
    "section": "1.2 This Course",
    "text": "1.2 This Course\n\n1.2.1 Course Description\nAs a response to this issue, econometricians have developed a range of statistical techniques that are suitable for observational data and robust to unobserved heterogeneity in varying senses. This course surveys some of the most important advances, structured into three key topics:\n\nLinear models with heterogeneous coefficients: extending traditional regression models to allow for individual-specific responses to treatment.\nNonparametric models with unobserved heterogeneity: models that do not restrict the form of heterogeneity or how it affects the outcome.\nQuantile and distribution regression: approaches that focus on quantile and distributional treatment effects, rather than the distribution of treatment effects.\n\nThroughout, we will focus on non-experimental (observational) data, where unobserved heterogeneity cannot be ignored. We will emphasize identification strategies over asymptotic theory.\n\n\n1.2.2 Common Themes\nDespite their differences, all models we study in this course share a common structure: they describe how an outcome \\(y\\) depends on observed factors (\\(x\\)) and unobserved heterogeneity (\\(u, \\alpha\\)). At a general level, this can be expressed as the cross-sectional and panel potential outcomes models: \\[\n    y_i(x) = \\phi(x, \\alpha_i),  \\quad y_{it}(x) = \\phi(x, \\alpha_i, u_{it}),\n\\tag{1.1}\\] where \\(x\\) is some potential value of the observed covariates, \\(\\alpha_i\\) and \\(u_{it}\\) are the time-invariant and time-varying unobserved characteristics of unit \\(i\\), respectively; and \\(y_i(x)\\) and \\(y_{it}(x\\) are the (scalar) outcome for individual \\(i\\) given \\(x\\) (in time \\(t\\)). In practice, we will have access to datasets of the form \\(\\curl{(y_i, x_i)}_{i=1, \\dots, N}\\) or \\(\\curl{(y_{it}, x_{it})}_{i=1,\\dots, N}^{t=1, \\dots, T}\\). The observed outcomes are generated as \\[\n    y_i = \\phi(x_i, \\alpha_i),  \\quad y_{it} = \\phi(x_{it}, \\alpha_i, u_{it}),\n\\]\nThroughout, our goal will be to learn different features of the potential outcomes, such as average effects or the full individual-level structural functions.\nA common theme is that there always will be a price to pay for learning any feature of the counterfactual distribution. This price is paid in the form of assumptions and restrictions on the model (1.1) — another manifestation of the fundamental problem of causal inference. Some potential courses of action will include:\n\nImposing functional form restrictions on \\(g\\) (e.g. parametric assumptions such as linearity, or assuming that \\(\\alpha_i\\) is scalar and that it affects \\(g\\) monotonically);\nRestricting the extent of unobserved heterogeneity in the model (e.g. assuming that there is scalar unobserved variables or a vector of heterogeneous coefficients);\nRestricting the relationship between the observed and unobserved variables (e.g. assuming that \\(\\alpha_i\\) is independent from \\(x_i\\));\nFocusing on particular parts of the distribution of the outcome (such as quantiles).\n\nWe will see examples of each approach throughout the course, and one should see each particular model discussed as a specific variation of model (1.1).\n\n\nNext Section\nIn the next section, we begin by examining how unobserved heterogeneity arises naturally in linear models and setting the stage for the first block of the course.\n\n\n\n\nStefanski, Leonard A., and Raymond J. Carroll. 1985. “Covariate Measurement Error in Logistic Regression.” The Annals of Statistics 13 (4): 1335–51. https://doi.org/10.1214/aos/1176349741.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "linear/linear-introduction.html",
    "href": "linear/linear-introduction.html",
    "title": "2  Intro: Linear Models with Heterogeneous Coefficients",
    "section": "",
    "text": "2.1 Linearity and Heterogeneity",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Intro: Linear Models with Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-introduction.html#linearity-and-heterogeneity",
    "href": "linear/linear-introduction.html#linearity-and-heterogeneity",
    "title": "2  Intro: Linear Models with Heterogeneous Coefficients",
    "section": "",
    "text": "2.1.1 Models with Homogeneous Slopes\nWe begin our journey where standard textbooks and first-year foundational courses in econometrics leave off. The “standard” linear models considered in such courses often assume homogeneity in individual responses to covariates (e.g., Hansen (2022)). A common cross-sectional specification is:\n\\[\ny_i = \\bbeta'\\bx_i + u_{i},\n\\tag{2.1}\\] where \\(i=1, \\dots, N\\) indexes cross-sectional units.\nIn panel data, models often include unit-specific \\((i)\\) and time-specific \\((t)\\) intercepts while maintaining a common slope vector \\(\\bbeta\\):\n\\[\ny_{it} = \\alpha_i + \\delta_t +  \\bbeta'\\bx_{it} + u_{it}.\n\\tag{2.2}\\]\n\n\n2.1.2 Heterogeneity in Slopes. Examples\nHowever, modern economic theory rarely supports the assumption of homogeneous slopes \\(\\bbeta\\). Theoretical models recognize that observationally identical individuals, firms, and countries can respond differently to the same stimulus. In a linear model, this requires us to consider more flexible models with heterogeneous coefficients:\n\nCross-sectional model (2.1) generalizes to\n\\[\ny_i = \\bbeta_{i}'\\bx + u_i.\n\\tag{2.3}\\]\nPanel data model (2.2) generalizes to\n\\[\ny_{it}  = \\bbeta_{it}'\\bx_{it} + u_{it}.\n\\tag{2.4}\\]\n\nSuch models are worth studying, as they naturally arise in a variety of contexts:\n\nStructural models with parametric restrictions: Certain parametric restrictions yield linear relationships in coefficients. An example is given by firm-level Cobb-Douglas production functions where firm-specific productivity differences induce heterogeneous coefficients (Combes et al. (2012); Sury (2011)).\nBinary covariates and interaction terms: if all covariates are binary and all interactions are included, a linear model encodes all treatment effects without loss of generality (see, e.g., Wooldridge (2005)).\nLog-linearized models: Nonlinear models may be approximated by linear models around a steady-state. For example, Heckman and Vytlacil (1998) demonstrate how the nonlinear Card (2001) education model simplifies to a heterogeneous linear specification after linearization.",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Intro: Linear Models with Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-introduction.html#what-do-we-care-about-identification",
    "href": "linear/linear-introduction.html#what-do-we-care-about-identification",
    "title": "2  Intro: Linear Models with Heterogeneous Coefficients",
    "section": "2.2 What Do We Care About? Identification",
    "text": "2.2 What Do We Care About? Identification\n\n2.2.1 Parameters of Interest\nThe parameters of interest in models (2.1) and (2.2) are straightforward. The common slope \\(\\bbeta\\) simultaneously plays the role of both the average treatment effect and all the individual treatment effects. Estimating \\(\\bbeta\\) is enough for policy analysis.\nThe situation is more complicated for the more general models (2.3) and (2.4). Consider model (2.3). Parameters of interest now include:\n\nIndividual effects: the coefficient vector \\(\\bbeta_i\\) for specific units.\nMoments of the distribution: the average coefficient vector (\\(\\E[\\bbeta_i]\\)), variance \\(\\var(\\bbeta_i)\\), and higher-order moments.\nDistributional properties: The full distribution of \\(\\bbeta_i\\) or its quantiles, or just the tail behavior of the distribution.\n\nSimilar objects are relevant for the panel model in Equation 2.4.\n\n\n2.2.2 Regarding Identification\nUnfortunately, greater flexibility in terms of parameters also leads to greater challenges in terms of identification. Models (2.3) and (2.4) are too general to permit identification of any of the above parameters without further assumptions. This failure of identification is driven by the combination of the following two issues:\n\nLimited observations per coefficient vector. Since each unit \\(i\\) (or pair \\((i,t)\\)) provides only indirect information through \\(\\bbeta_i'\\bx_i\\) (or \\(\\bbeta_{it}'\\bx_{it}\\)), there is effectively less than one observation per \\(\\bbeta_i\\).\nUnrestricted dependence between coefficients and covariates. Without assumptions on the relationship between \\(\\bbeta_i\\) and \\(\\bx_i\\), identification is difficult.\n\nIdentification is typically achieved by mitigating one of these challenges. Common strategies to address these challenges include:\n\nIncreasing the effective number of observations per coefficient vector by restricting coefficient variation.\n\nIn panel settings, assuming time-invariant coefficients simplifies Equation 2.4 to:\n\\[\ny_{it} = \\bbeta_i'\\bx_{it} + u_{it}.\n\\tag{2.5}\\]\nAlternative approaches assume a finite number of latent groups, each with its own coefficient vector, yielding the grouped structure:\n\\[\ny_{it} = \\bbeta_{g_i, t}'\\bx_{it} + u_{it}.\n\\tag{2.6}\\]\nThis model in Bonhomme and Manresa (2015), Bester and Hansen (2016), and Bonhomme, Lamadon, and Manresa (2022).\n\nRestricting dependence between \\(\\bbeta_i\\) and \\(\\bx_i\\). For example, there is a strand of literature that assumes that \\(\\bbeta_i\\) and \\(\\bx_i\\) are independent (Beran, Feuerverger, and Hall 1996; Hoderlein, Klemelä, and Mammen 2010).",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Intro: Linear Models with Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-introduction.html#model-of-this-block",
    "href": "linear/linear-introduction.html#model-of-this-block",
    "title": "2  Intro: Linear Models with Heterogeneous Coefficients",
    "section": "2.3 Model of This Block",
    "text": "2.3 Model of This Block\nThis block primarily focuses on the first strategy. Specifically, we will consider a version of model (2.4) with time-invariant heterogeneous coefficients:\n\\[\ny_{it} = \\bbeta_i'\\bx_{it} + u_{it}.\n\\tag{2.7}\\]\nWe do not impose restrictions on the dependence between \\(\\bbeta_i\\) and \\(\\bx_{it}\\). In general, it is important to allow for such dependence outside of experimental data — economic agents can select their covariates \\(\\bx_{it}\\) based on knowledge of their own \\(\\bbeta_i\\). Since parametrizing this dependence is non-trivial, we impose no assumptions on it.\nWe will also generally focus on the case where the number \\(N\\) of units is large, while the number \\(T\\) of observations per unit is fixed and not necessarily large.\n\n\n\n\n\n\nIn the panel data literature, approaches that do not restrict the dependence between the unobserved and the observed components are called “fixed effects”.\n\n\n\nNote that model (2.7) includes a particular special case — the random intercept model (confusingly also called the “fixed effects model”). The random intercept model imposes homogeneity on all parameters except the intercept term. In the one-way case, the model takes the form:\n\\[\ny_{it} = \\alpha_i + \\bbeta'\\bx_{it} + u_{it}.\n\\tag{2.8}\\] Model (2.8) is one of the oldest ways of including unobserved heterogeneity in linear models and goes back at least to Mundlak (1961).",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Intro: Linear Models with Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-introduction.html#plan-for-this-block",
    "href": "linear/linear-introduction.html#plan-for-this-block",
    "title": "2  Intro: Linear Models with Heterogeneous Coefficients",
    "section": "2.4 Plan for This Block",
    "text": "2.4 Plan for This Block\nIn this block, we will focus on model (2.7) and consider identification of the above parameters of interest. Specifically,\n\nAverage coefficient vector \\(\\E[\\bbeta_i]\\):\n\nFirst, we demonstrate that standard estimators for the random intercept model (2.8) are generally inconsistent for \\(\\E[\\bbeta_i]\\) in the more general model (2.7).\nNext, we introduce a mean group estimator robust to heterogeneity and dynamics.\n\nVariance \\(\\var(\\bbeta_i)\\): we show how one can identify and estimate \\(\\var(\\bbeta_i)\\) by imposing structure on the temporal dependence in the residuals \\(u_{it}\\).\nIdentifying the Full Distribution of \\(\\bbeta_i\\): we show how one can obtain the distribution of \\(\\bbeta_i\\) with a deconvolution argument.\n\n\n\nNext Section\nNext, we show that the within (fixed effects) estimator recovers \\(\\E[\\bbeta_i]\\) only under restrictive assumptions.\n\n\n\n\nBeran, Rudolf, Andrey Feuerverger, and Peter Hall. 1996. “On Nonparametric Estimation of Intercept and Slope Distributions in Random Coefficient Regression.” The Annals of Statistics 24 (6): 2569–92. https://doi.org/10.1214/aos/1032181170.\n\n\nBester, C Alan, and Christian B Hansen. 2016. “Grouped Effects Estimators in Fixed Effects Models.” Journal of Econometrics 190 (1): 197–208. https://doi.org/10.1016/j.jeconom.2012.08.022.\n\n\nBonhomme, Stéphane, Thibaut Lamadon, and Elena Manresa. 2022. “Discretizing Unobserved Heterogeneity.” Econometrica 90 (2): 625–43. https://doi.org/10.3982/ECTA15238.\n\n\nBonhomme, Stéphane, and Elena Manresa. 2015. “Grouped Patterns of Heterogeneity in Panel Data.” Econometrica 83 (3): 1147–84. https://doi.org/10.3982/ecta11319.\n\n\nCard, David. 2001. “Estimating the Return to Schooling: Progress on Some Persistent Econometric Problems.” Econometrica 69 (5): 1127–60. https://doi.org/10.1111/1468-0262.00237.\n\n\nCombes, Pierre Philippe, Gilles Duranton, Laurent Gobillon, Diego Puga, and Sébastien Roux. 2012. “The Productivity Advantages of Large Cities: Distinguishing Agglomeration From Firm Selection.” Econometrica 80 (6): 2543–94. https://doi.org/10.3982/ecta8442.\n\n\nHansen, Bruce. 2022. Econometrics. Princeton University Press.\n\n\nHeckman, James, and Edward Vytlacil. 1998. “Instrumental variables methods for the correlated random coefficient model.” Journal of Human Resources 33 (4): 974–87.\n\n\nHoderlein, Stefan, Jussi Klemelä, and Enno Mammen. 2010. “Analyzing the Random Coefficient Model Nonparametrically.” Econometric Theory 26 (03): 804–37. https://doi.org/10.1017/S0266466609990119.\n\n\nMundlak, Yair. 1961. “Empirical Production Function Free of Management Bias.” Journal of Farm Economics 43 (1): 44. https://doi.org/10.2307/1235460.\n\n\nSury, Tavneet. 2011. “Selection and Comparative Advantage in Technology Adoption.” Econometrica 79 (1): 159–209. https://doi.org/10.3982/ecta7749.\n\n\nWooldridge, Jeffrey M. 2005. “Fixed-effects and related estimators for correlated random-coefficient and treatment-effect panel data models.” The Review of Economics and Statistics 87 (May): 385–90.",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Intro: Linear Models with Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-within-estimator.html",
    "href": "linear/linear-within-estimator.html",
    "title": "3  Within (Fixed Effects) Estimator and Heterogeneous Coefficients",
    "section": "",
    "text": "3.1 Introduction\nAs noted in the previous section, in this block we will focus our attention on the linear panel data model with unit-specific heterogeneous coefficients (Equation 2.7): \\[\ny_{it} = \\bbeta_i'\\bx_{it} + u_{it}.\n\\tag{3.1}\\]\nOur first key parameter of interest is the average coefficient vector \\(\\E[\\bbeta_i]\\) — the linear model analog to the average treatment effect.",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Within (Fixed Effects) Estimator and Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-within-estimator.html#introduction",
    "href": "linear/linear-within-estimator.html#introduction",
    "title": "3  Within (Fixed Effects) Estimator and Heterogeneous Coefficients",
    "section": "",
    "text": "3.1.1 Focus: Workhorse Estimators under Heterogeneity\nCan existing workhorse estimators for linear panel data models — the within (fixed effects) and dynamic panel IV estimators — correctly estimate \\(\\E[\\bbeta_i]\\)? Of course, those methods were developed in the context of the simpler random intercept model (2.8) \\[\ny_{it} = \\alpha_i + \\bbeta'\\bx_{it} + u_{it}.\n\\tag{3.2}\\] However, if they can also handle the more general Equation 3.1, then all the better for us — we do not need to develop any new methods.\nUnfortunately, such standard estimators usually fail when coefficients vary across units, as we will demonstrate This failure holds both for static and the dynamic formulations of Equation 3.1.\n\n\n3.1.2 This Section: Static Model and Fixed \\(T\\)\nIn this section, we consider the static case and the associated workhorse estimator — the within (fixed effects) estimator. By “static”, we mean that the model does not include lagged dependent variables as regressors. In addition, we assume strict exogeneity \\[\n\\E[\\bu_i|\\bX_i]=0.\n\\]\nThroughout, we will assume that the number \\(N\\) of cross-sectional units is potentially large, while the number \\(T\\) of data points per unit is fixed. This setup is more reflective of typical micropanels.",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Within (Fixed Effects) Estimator and Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-within-estimator.html#recall-within-estimator-in-the-random-intercept-model",
    "href": "linear/linear-within-estimator.html#recall-within-estimator-in-the-random-intercept-model",
    "title": "3  Within (Fixed Effects) Estimator and Heterogeneous Coefficients",
    "section": "3.2 Recall: Within Estimator in the Random Intercept Model",
    "text": "3.2 Recall: Within Estimator in the Random Intercept Model\nTo begin, we will briefly go through the construction and the properties of the within estimator under the random intercept model (3.2).\n\n3.2.1 Construction\nWithin (“fixed effects”) estimation of the random intercept model has two steps:\n\nApply the within transformation to each unit.\nApply OLS to the resulting pooled data.\n\n\n3.2.1.1 Step 1: Within Transformation\nTo perform the within transformation, we first average the equations for unit \\(i\\) across \\(t\\). Label the average of \\(y_{it}\\) across \\(t\\) for unit \\(i\\) as\n\\[\ny_{i\\cdot} = \\frac{1}{T} \\sum_{t=1}^{T} y_{it}.\n\\]\nThe averaged outcome \\(y_{i\\cdot}\\) satisfies the averaged equation\n\\[\ny_{i\\cdot} = \\alpha_i + \\bbeta' \\bx_{i\\cdot} + u_{i\\cdot},\n\\] where \\(\\bx_{i\\cdot}\\) and \\(u_{i\\cdot}\\) are defined analogously to \\(y_{i\\cdot}\\).\nDefine the within-transformed variables by subtracting this averaged equation from the original equation for each \\(t\\): \\[\n\\tilde{y}_{it} = y_{it} - y_{i\\cdot}.\n\\]\nIf Equation 3.2 is true, the within transformed variables follow the within-transformed equation:\n\\[\n\\tilde{y}_{it} = \\bbeta' \\tilde{\\bx}_{it} + \\tilde{u}_{it}.\n\\tag{3.3}\\]\nUnder Equation 3.2, the within transformation eliminates the individual random intercepts \\(\\alpha_i\\). Equation 3.3 now looks like a regular homogeneous regression.\n\n\n3.2.1.2 Step 2: OLS on the Within-Transformed Equation\nThe within (fixed effects) estimator is obtained by simply pooling the data across \\(i\\) and \\(t\\) in Equation 3.3 and applying OLS to it. Specifically, the estimator is given by\n\\[\n\\hat{\\bbeta}^W = \\left(\\sum_{i=1}^{N} \\tilde{\\bX}_i' \\tilde{\\bX}_i \\right)^{-1} \\sum_{i=1}^{N} \\tilde{\\bX}_i \\tilde{\\mathbf{y}}_i.\n\\tag{3.4}\\]\n\n\n\n3.2.2 Properties\nThe within estimator enjoys several desirable properties under the random intercept model, most of which can be derived from its sampling error representation \\[\n\\hat{\\bbeta}^W = \\bbeta + \\left(\\sum_{i=1}^{N} \\tilde{\\bX}_i' \\tilde{\\bX}_i \\right)^{-1} \\sum_{i=1}^{N} \\tilde{\\bX}_i \\tilde{\\bu}_i.\n\\tag{3.5}\\]\n\n\\(\\hat{\\bbeta}^W\\) is unbiased for \\(\\bbeta\\). To show this, it is sufficient to notice that strict exogeneity of \\(\\bu_i\\) with respect to \\(\\bX_i\\) implies strict exogeneity of \\(\\tilde{\\bu}_i\\) with respect to \\(\\tilde{\\bX}_i\\): \\[\n\\E[\\tilde{\\bu}_i|\\tilde{\\bX}_i] =\n\\E[\\E[\\tilde{\\bu}_i|\\bX_i]|\\tilde{\\bX}_i] = 0.\n\\] It follows that the mean of the second term in Equation 3.5 is 0, and so \\[\n\\E[\\hat{\\bbeta}^W] = \\bbeta.\n\\]\n\\(\\hat{\\bbeta}^W\\) is consistent for \\(\\bbeta\\) and asymptotically normal, provided a standard rank condition holds for \\(\\tilde{\\bX}_i\\): \\[\n\\hat{\\bbeta}^W \\xrightarrow{p} \\bbeta, \\quad \\sqrt{N}(\\hat{\\bbeta}^W - \\bbeta) \\Rightarrow N(0, \\Sigma).  \n\\tag{3.6}\\]\n\nSince \\(\\bbeta\\) is the average coefficient vector in this homogeneous model, we conclude that the within estimator consistently estimates average coefficients under the random intercept model (3.2).",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Within (Fixed Effects) Estimator and Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-within-estimator.html#adding-heterogeneous-coefficients",
    "href": "linear/linear-within-estimator.html#adding-heterogeneous-coefficients",
    "title": "3  Within (Fixed Effects) Estimator and Heterogeneous Coefficients",
    "section": "3.3 Adding Heterogeneous Coefficients",
    "text": "3.3 Adding Heterogeneous Coefficients\nHowever, there is usually no theoretical reason for the slopes \\(\\bbeta\\) to be homogeneous. An assumption of slope homogeneity goes against acknowledging heterogeneity and including the random intercept terms \\(\\alpha_i\\) in the first place. It is rather more realistic to consider the more general Equation 3.1. Accordingly, we now turn to studying the properties of \\(\\hat{\\bbeta}^W\\) in this more realistic setting.\n\n3.3.1 Sampling Error Form\nApplying the within transformation to the heterogeneous Equation 3.1 yields another version of the within-transformed equation:\n\\[\n\\tilde{y}_{it} = \\bbeta_i' \\tilde{\\bx}_{it} + \\tilde{u}_{it}.\n\\]\nNote that now the individual heterogeneity is not eliminated! The heterogeneous coefficients \\(\\bbeta_i\\) remain in the equation.\nThe within estimator on the above equation may then be represented as \\[\n\\begin{aligned}\n\\hat{\\bbeta}^W  & = \\left(\\sum_{i=1}^N \\tilde{\\bX}_i'\\tilde{\\bX}_i \\right)^{-1} \\sum_{i=1}^N \\tilde{\\bX}_i \\tilde{\\by}_i \\\\\n& = \\left(\\sum_{i=1}^N \\tilde{\\bX}_i'\\tilde{\\bX}_i \\right)^{-1} \\sum_{i=1}^N \\tilde{\\bX}_i \\tilde{\\bX}_i\\bbeta_i + \\left(\\sum_{i=1}^N \\tilde{\\bX}_i'\\tilde{\\bX}_i \\right)^{-1} \\sum_{i=1}^N \\tilde{\\bX}_i \\tilde{\\bu}_i.\n\\end{aligned}\n\\] Note the difference of the sampling error representation with Equation 3.5. The first term is now a weighted average of the individual coefficients. The weights themselves depend on the second moments of the within-transformed explanatory variables, which may be viewed as a kind of variance weighting for units.\nDoes the within estimator target \\(\\E[\\bbeta_i]\\)? To proceed, we decompose \\(\\bbeta_i\\) into a common mean component \\(\\E[\\bbeta_i]\\) and an idiosyncratic deviation \\(\\bEta_i\\): \\[\n\\bbeta_i = \\E[\\bbeta_i] + \\bEta_i\n\\]\nWith this representation, we can further analyze the within estimator as \\[\n\\begin{aligned}\n    \\hat{\\bbeta} & = \\E[\\bbeta_i]  + \\left( \\dfrac{1}{N}\\sum_{i=1}^N \\tilde{\\bX}_i'\\tilde{\\bX}_i \\right)^{-1}  \\dfrac{1}{N}\\sum_{i=1}^N \\tilde{\\bX}_i \\tilde{\\bX}_i\\bEta_i \\\\\n    &  \\phantom{ = \\E[\\bbeta_i] } + \\left( \\dfrac{1}{N}\\sum_{i=1}^N  \\tilde{\\bX}_i'\\tilde{\\bX}_i \\right)^{-1} \\dfrac{1}{N}\\sum_{i=1}^N \\tilde{\\bX}_i \\tilde{\\bu}_i\\\\\n    & \\xrightarrow{p} \\E[\\bbeta_i]  + \\left(\\E\\left[\\tilde{\\bX}_i'\\tilde{\\bX}_i \\right] \\right)^{-1} \\E\\left[\\tilde{\\bX}_i'\\tilde{\\bX}_i\\bEta_i \\right]  \\\\\n  &    \\phantom{ = \\E[\\bbeta_i] }  + \\left(\\E\\left[\\tilde{\\bX}_i'\\tilde{\\bX}_i \\right] \\right)^{-1} \\E\\left[\\tilde{\\bX}_i'\\tilde{\\bu}_i \\right]\\\\\n    & = \\E[\\bbeta_i] + \\left(\\E\\left[\\tilde{\\bX}_i'\\tilde{\\bX}_i \\right] \\right)^{-1} \\E\\left[\\tilde{\\bX}_i'\\tilde{\\bX}_i\\bEta_i \\right],\n\\end{aligned}\n\\] where we have assumed that a suitable law of large numbers applies as \\(N\\to\\infty\\) and \\(T\\) is fixed, and where \\(\\E\\left[\\tilde{\\bX}_i'\\tilde{\\bu}_i \\right]=0\\) as above.\n\n\n3.3.2 Conditions for Estimating Average Coefficients\nThe above representation shows that the within estimator is not estimating \\(\\E[\\bbeta_i]\\) unless the following orthogonality condition holds: \\[\n    \\E\\left[\\tilde{\\bX}_i'\\tilde{\\bX}_i\\bEta_i \\right] =0.\n\\tag{3.7}\\] Even though \\(\\E[\\bEta_i]=0\\), the above condition does not necessarily hold if \\(\\bbeta_i\\) and \\(\\bX_i\\) are allowed to dependent.\nIf condition (3.7) holds, the within estimator is consistent for \\(\\E[\\bbeta_i]\\) in the heterogeneous coefficient model (3.1). If it fails, the estimator is biased. The difference between the estimand and \\(\\E[\\bbeta_i]\\) is known as heterogeneity bias (see Campello, Galvao, and Juhl 2019 in the linear case).\nThis orthogonality condition (3.7) is a bit complicated to understand. A simpler sufficient condition is a mean independence on the coefficients given the within transformed covariates: \\[\n\\E[\\boldsymbol{\\eta}_i|\\tilde{\\bX}_i] = 0.  \n\\tag{3.8}\\] Under this condition \\(\\E[\\tilde{\\bX}_i'\\tilde{\\bX}_i\\bEta_i] =0\\), and thus the within estimator is consistent for \\(\\E[\\bbeta_i]\\). These conditions were proposed by Wooldridge (2003), Wooldridge (2005) (see all Murtazashvili and Wooldridge (2008) for the IV within estimator case).\n\n\n\n\n\n\nConditions (3.7) and (3.8) restrict the dependence structure between \\(\\bbeta_i\\) and \\(\\bx_{it}\\). Such conditions are sometimes called correlated random effects (CRE) in the literature. CRE assumptions lie between fixed effects (FE) frameworks — which do not restrict the dependence — and random effects (RE) — which assume that unobserved components are independent of the observed ones.\n\n\n\n\n\n3.3.3 Intuition\nHow can we interpret condition (3.8)? Intuitively, it requires that the changes in \\(\\bx_{it}\\) over time are uncorrelated with the individual coefficients.\nTo see this interpretation, it is helpful to think of the following example framework. Suppose that \\(\\bx_{it}\\) is stationary, that is, its distribution does not depend on \\(t\\). Decompose \\(\\bx_{it}\\) as \\[\n\\bx_{it} = \\E[\\bx_{it}|\\bbeta_i]  + \\bxi_{it},\n\\]\nThen the within transformed variables satisfy: \\[\n    \\tilde{\\bx}_{it} = \\tilde{\\bxi}_{it}.\n\\]\nThe “systemic” component \\(\\E[\\bx_{it}|\\bbeta_i]\\) is not present in \\(\\tilde{\\bx}_{it}\\). Only the deviations across time \\(\\tilde{\\bxi}_{it}\\) are left. Condition (3.8) requires that \\(\\tilde{\\bxi}_{it}\\) and \\(\\bEta_i\\) are unrelated on average. Note that it permits an arbitrary relationship between \\(\\bbeta_i\\) and \\(\\E[\\bx_{it}|\\bbeta_i]\\).\nAs an example, suppose that we are working with consumption data. A consumer knows their marginal utilities \\(\\bbeta_i\\) of consuming more of a variety of products. With this knowledge, they choose the optimal desired level of consumption — \\(\\E[\\bx_{it}|\\bbeta_i]\\). When they try to buy this level of products, they may encounter some frictions \\(\\bxi_{it}\\) which cause them to deviate from \\(\\E[\\bx_{it}|\\bbeta_i]\\) — in rough words, the supermarket might not have their favorite cereal. If these “frictions” are uncorrelated with \\(\\bbeta_i\\), then the required consistency will hold. In the consumption example, this fact means that unpredictable deviation in short-term choices do not necessarily bias the estimation of overall preferences.\n\n\n3.3.4 Why Panel Data is Useful\nIt is useful to contrast condition 3.8 with the stronger condition that \\[\n\\E[\\bEta_i|\\bX_i]=0.\n\\tag{3.9}\\] Note the difference in the conditioning sets.\nCondition (3.9) is stronger than (3.8) by the tower property of conditional expectation. Intuitively, we can compute \\(\\tilde{\\bX}_i\\) from \\(\\bX_i\\), but not vice versa. The requirement that \\(\\E[\\bEta_i|\\bX_i]=0\\) may be very strong, since it would in general require that \\(\\E[\\bx_{it}|\\bbeta_i]\\) does not depend on \\(\\bbeta_i\\) — we rule out a systemic dependence even on average.\nThis contrast also highlights the advantages of panel data. If you want to consistently estimate \\(\\E[\\bbeta_i]\\) using OLS and cross-sectional data, you need the very strong condition (3.9) or at least that \\(\\E[\\bx_i\\bx_i'\\bbeta_i]=0\\). With panel data, weaker conditions are sufficient, and systemic dependence between \\(\\bbeta_i\\) and \\(\\bx_{it}\\) is possible.\n\n\n3.3.5 Example\nWe conclude this section with a small illustration of the results in a tractable model (see this blog post for a simulation with some dramatic examples). Specifically, we consider the following panel model with two periods, coefficient heterogeneity, and a scalar regressor: \\[\ny_{it} = \\alpha_i + \\beta_i x_{it} + u_{it}, \\quad t=1,2.\n\\]\nwhere \\(\\bX_{it}\\) and \\(\\bbeta_i\\) are jointly normal:\n\\[\n\\begin{aligned}\n    \\begin{pmatrix}\n      x_{i1}\\\\\n      x_{i2}\\\\\n      \\beta_i\n    \\end{pmatrix} \\sim N\\left(  \\begin{pmatrix}\n    1\\\\\n    2\\\\\n    0.5\n    \\end{pmatrix}, \\begin{pmatrix}\n    1 & \\rho_{1, \\beta}\\rho_{2, \\beta} & \\rho_{1, \\beta}\\\\\n    \\rho_{1, \\beta}\\rho_{2, \\beta} & 1 & \\rho_{2, \\beta}\\\\\n    \\rho_{1, \\beta} & \\rho_{2, \\beta} & 1\n    \\end{pmatrix}   \\right),\n\\end{aligned}\n\\tag{3.10}\\] where the various \\(\\rho\\) parameters are correlations. The correlation between \\(x_{i1}\\) and \\(x_{i2}\\) is such that they are only correlated through \\(\\beta_i\\). The distribution of the \\(\\alpha_i\\) does not have to be specified, as it is not involved in the consistency conditions. Likewise, we only need to assume that \\(\\E[u_{it}|x_{i1}, x_{i2}]=0\\) without further specifying the distribution of \\(u_{it}\\).\nThe within transformations yields the following equation: \\[\n                y_{i2} - y_{i1} = \\beta_i(x_{i2}-x_{i1}) + (u_{i2}-u_{i1})\n\\] The mean independence condition 3.8 takes form \\[\n    \\E[ \\beta_i|x_{i2} - x_{i1}]  = 0.5.\n\\]\nIt is not difficult to work out (Brockwell and Davis 2016, A.3.1) that \\[\n\\E[ \\beta_i|x_{i2} - x_{i1}]  = 0.5 + (\\rho_{2, \\beta}- \\rho_{1, \\beta})(x_{i2} - x_{i1} - 1)\n\\] Thus, \\(\\E[ \\beta_i|x_{i2} - x_{i1}]=0.5\\) only holds if \\[\n\\rho_{2, \\beta} = \\rho_{1, \\beta}.\n\\tag{3.11}\\] In this case, \\(x_{it}\\) becomes stationary, and does not have dynamics that depend on \\(\\beta_i\\) in the mean.\nIf condition 3.11 holds, the within estimator is consistent. It is also possible to show that if condition 3.11 fails, so does the more general Equation 3.7, and the within estimator is inconsistent. We represent this fact on Figure 3.1, where we fix \\(\\rho_{1, beta}=0.25\\), and vary \\(\\rho_{2, \\beta}\\) between \\(-1\\) and \\(1\\). Observe that the within estimator is consistent if \\(\\rho_{2, \\beta} = \\rho_{1, \\beta} = 0.25\\). Otherwise, it is biased, potentially severely. For \\(\\rho_{2, \\beta}\\leq -0.6\\), the estimand of the within estimator has a sign different from that of \\(\\E[\\beta_i]\\).\n\n\n\n\n\n\nFigure 3.1: The within estimator under coefficient heterogeneity. Consistency and inconsistency for the average coefficient under data generating process (3.10)\n\n\n\n\n\nNext Section\nIn the next section, we turn to the dynamic case and briefly introduce the “standard” dynamic panel instrumental variable estimators.\n\n\n\n\nBrockwell, Peter J., and Richard A. Davis. 2016. Introduction to Time Series and Forecasting. Springer Texts in Statistics. Springer International Publishing.\n\n\nCampello, Murillo, Antonio F. Galvao, and Ted Juhl. 2019. “Testing for Slope Heterogeneity Bias in Panel Data Models.” Journal of Business and Economic Statistics 37 (4): 749–60. https://doi.org/10.1080/07350015.2017.1421545.\n\n\nMurtazashvili, Irina, and Jeffrey M. Wooldridge. 2008. “Fixed effects instrumental variables estimation in correlated random coefficient panel data models.” Journal of Econometrics 142 (1): 539–52. https://doi.org/10.1016/j.jeconom.2007.09.001.\n\n\nWooldridge, Jeffrey M. 2003. “Fixed Effects Estimation of the Population-Averaged Slopes in a Panel Data Random Coefficient Model.” Econometric Theory 19: 411–13. https://doi.org/10+10170S0266466603002081.\n\n\n———. 2005. “Fixed-effects and related estimators for correlated random-coefficient and treatment-effect panel data models.” The Review of Economics and Statistics 87 (May): 385–90.",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Within (Fixed Effects) Estimator and Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-dynamic-panel-iv.html",
    "href": "linear/linear-dynamic-panel-iv.html",
    "title": "4  Interlude: Standard Dynamic Panel Estimators",
    "section": "",
    "text": "4.1 Exogeneity and Dynamic Models",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interlude: Standard Dynamic Panel Estimators</span>"
    ]
  },
  {
    "objectID": "linear/linear-dynamic-panel-iv.html#exogeneity-and-dynamic-models",
    "href": "linear/linear-dynamic-panel-iv.html#exogeneity-and-dynamic-models",
    "title": "4  Interlude: Standard Dynamic Panel Estimators",
    "section": "",
    "text": "4.1.1 Introduction\nThroughout the previous section, we assumed that the idiosyncratic term \\(u_{it}\\) satisfied strict exogeneity with respect to the data: \\[\n    \\E[u_{it}|\\bX_i] = 0.\n\\tag{4.1}\\]\nHowever, strict exogeneity is not an innocent assumption. In particular, it implies that for all pairs of indices \\(t, s\\) it holds that \\[\n    \\E[u_{it}\\bx_{is}] =0.\n\\tag{4.2}\\]\nFor \\(t&lt;s\\), Equation 4.2 means that past shocks are uncorrelated with future values of \\(\\bx\\). In other words, one cannot predict past shocks from future \\(\\bx\\)s.\nThis requirement might fail if \\(\\bx\\) is dynamic and its evolution is affected by \\(u_{it}\\). In this section, we will discuss this challenge and some traditional approaches to dealing with it with short panel data.\n\n\n4.1.2 No Strict Exogeneity for Dynamic Models\nA particularly clear example for failure of Equation 4.2 arises when \\(\\bx_{it}\\) includes lagged values of the outcome. As we show now, strict exogeneity cannot hold in this case.\nFor simplicity, we momentarily forget about the cross-sectional dimension and consider a simple autoregressive model with 1 lag (AR(1)): \\[\n    y_t = \\alpha + \\lambda y_{t-1} + u_{t},\n\\] where \\(t=1, \\dots, T\\) and the innovation \\(u_t\\) satisfies \\(\\E[u_t]=0\\).\nTo show that strict exogeneity fails, it is sufficient to find a single pair of \\((t, s)\\) such that Equation 4.2 is not true. Specifically, we will take \\(s=t+1\\) and show that \\(\\E[y_{it+1}u_t]\\) is not necessarily zero.\nTo evaluate this expectation, we write the model at \\(t+1\\) \\[\n    y_{t+1} = \\alpha + \\lambda y_t + u_{t+1}.\n\\tag{4.3}\\] We then substitute the model into \\(\\E[y_{it+1}u_t]\\) \\[\n\\begin{aligned}\n    \\E[y_{t+1}u_t] & = \\lambda\\E[y_t u_t] + \\E[u_{t+1}u_t] \\\\\n    &  = \\lambda^2\\E[y_{t-1}u_t] + \\lambda\\E[u_t^2] + \\E[u_{t+1}u_t] .\n\\end{aligned}\n\\]\nWhat can we say about the right hand side? In many contexts, we may reasonably assume that\n\nOne cannot predict the shocks of tomorrow from what you have today, so that \\[\\E[y_{t-1}u_t]=0.\\]\n\\(u_{t}\\) is uncorrelated over time, so that \\[\\E[u_{t+1}u_t]=0.\\]\n\nHowever, \\(\\lambda\\E[u_t^2]\\) is zero only in two unreasonable cases:\n\nIf \\(\\lambda=0\\), and so the model is not actually dynamic\n\\(\\E[u_t^2]=0\\), and so the process is actually fully deterministic.\n\nBoth of these options are unpleasant. The first one goes against the idea of allowing any dynamics. The second is extremely unlikely with any kind of social data. We conclude that in dynamic models it is the case \\[\n\\E[y_{it+1}u_t] \\neq 0.\n\\tag{4.4}\\] A fortiori, strict exogeneity also cannot hold in dynamic models.\n\n\n4.1.3 Sequential Exogeneity\nSo what can you do if you want to allow for dynamic models? Since strict exogeneity (4.2) is effectively impossible to satisfy, we need a weaker form of exogeneity.\nOne popular weaker assumption compatible with dynamic models is sequential exogeneity (or predeterminedness). In context of the simple univariate time series model (4.3), sequential exogeneity may be stated as \\[\n        \\E[u_{t}| y_{t-1}, y_{t-2}, \\dots] =0.\n\\] Intuitively, sequential exogeneity states that future shocks cannot be predicted using past covariates. However, it does not restrict our ability to predict the past from the future — the context which created problems for strict exogeneity.\nMore generally, consider a panel data linear model with homogeneous coefficients, a random intercept, and a dynamic process for the outcome: \\[\ny_{it} = \\alpha_i + \\sum_{k=1}^K \\lambda_k y_{it-k} + \\bbeta'\\bx_{it} + u_{it}.  \n\\tag{4.5}\\] In this model, a sequential exogeneity assumption takes form \\[\n     \\E[u_{it}|\\curl{y_{is-1}, \\bx_{is}}_{s\\leq t}] =0.\n\\] Model (4.5) is a dynamic counterpart of the static model (3.2) we discussed in the last section.",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interlude: Standard Dynamic Panel Estimators</span>"
    ]
  },
  {
    "objectID": "linear/linear-dynamic-panel-iv.html#handling-dynamic-panels-with-a-random-intercept",
    "href": "linear/linear-dynamic-panel-iv.html#handling-dynamic-panels-with-a-random-intercept",
    "title": "4  Interlude: Standard Dynamic Panel Estimators",
    "section": "4.2 Handling Dynamic Panels with a Random Intercept",
    "text": "4.2 Handling Dynamic Panels with a Random Intercept\nBefore moving on and introducing heterogeneous coefficients in dynamic linear models, we will discuss model (4.5) in more detail. In particular, we will develop the standard workhorse instrumental variable estimators. We will analyze how these estimators fare in the more general model (2.7) in the next section.\n\n4.2.1 Model\nFor the sake of simplicity, we will discuss a simple version of model (4.5) without extra covariates \\(\\bx_{it}\\) and with only one lag of \\(y_{it}\\): \\[\ny_{it} = \\alpha_i + \\lambda y_{it-1} + u_{it},\n\\tag{4.6}\\] where \\(u_{it}\\) satisfies sequential exogeneity in the form \\(\\E[u_{it}|y_{is}, s&lt;t] = 0\\). This random intercept dynamic model has extensively considered in the literature (e.g. Anderson and Hsiao 1982; Arellano and Bond 1991; Blundell and Bond 1998).\nThe key parameter of interest is \\(\\lambda\\). By homogeneity of \\(\\lambda\\), it also plays the role of the average coefficient for model (4.6).\nHere, we will primarily focus on the large-\\(N\\), fixed-\\(T\\) case, though model (4.5) has also been extensively studied in the large-(\\(N, T\\)) case (e.g. Alvarez and Arellano 2003).\n\n\n4.2.2 Endogeneity\nTo work towards an estimator for \\(\\lambda\\), let us difference Equation 4.5 across \\(t\\) to eliminate the random intercept \\(\\alpha_i\\). The differenced equation takes form \\[\n\\begin{aligned}\n\\Delta y_{it} & = \\lambda \\Delta y_{it-1} + \\Delta u_{it}, \\\\\n\\Delta y_{it} & = y_{it} - y_{it-1}.\n\\end{aligned}\n\\tag{4.7}\\] Equation 4.7 seems like a simple regression equation. It is tempting to just apply OLS and regress \\(\\Delta y_{it}\\) on \\(\\Delta y_{it-1}\\).\nIt turns out that this approach will fail as there is an endogeneity problem in Equation 4.7! Sequential exogeneity is not enough to guarantee that \\[\n\\E[\\Delta y_{it-1}\\Delta u_{it}] = 0.\n\\]\nTo see why, we expand \\(\\E[\\Delta y_{it-1}\\Delta u_{it}]\\) as\n\\[\n\\begin{aligned}\n    & \\E\\left[(u_{it}-u_{it-1})(y_{it-1}-y_{it-2}) \\right] \\\\\n    & = \\E[ u_{it}y_{it-1} ] + \\E[(u_{it-1}-u_{it})y_{it-2}] - \\E[u_{it-1}y_{it-1}]  \\\\\n    & = -\\E[u_{it-1} y_{it-1}].\n\\end{aligned}\n\\] Sequential exogeneity is sufficient to immediately eliminate the first 2 expectations. For the last expectation remaining, we can substitute \\(y_{it-1}\\) to see that \\[\n\\begin{aligned}\n    \\E[u_{it-1}y_{it-1}] & = \\lambda\\E[u_{it-1}y_{it-2}] + \\E[u_{it-1}^2]\\\\\n    & = \\E[u_{it-1}^2]\n\\end{aligned}\n\\] As noted above, in general we expect that \\(\\E[u_{it-1}^2] \\neq 0\\). Hence we conclude that \\[\n    \\E[\\Delta y_{it-1}\\Delta u_{it}]\\neq 0.\n\\tag{4.8}\\] In other words, \\(\\Delta y_{it-1}\\) is an endogenous regressor in the differenced Equation 4.7.\n\n\n\n\n\n\nOne should not confuse endogeneity in Equation 4.8 with the failure of strict but not necessarily sequential exogeneity in dynamic models (e.g. Equation 4.4).",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interlude: Standard Dynamic Panel Estimators</span>"
    ]
  },
  {
    "objectID": "linear/linear-dynamic-panel-iv.html#iv-estimation-of-dynamic-panel-models",
    "href": "linear/linear-dynamic-panel-iv.html#iv-estimation-of-dynamic-panel-models",
    "title": "4  Interlude: Standard Dynamic Panel Estimators",
    "section": "4.3 IV Estimation of Dynamic Panel Models",
    "text": "4.3 IV Estimation of Dynamic Panel Models\nGiven the endogeneity issue in first-differencing, instrumental variable methods offer a potential solution. We only need to find suitable instruments — variables \\(z_{it}\\) which satisfy relevance and exogeneity conditions: \\[\n\\begin{aligned}\n    \\E[z_{it}\\Delta y_{it-1}] \\neq 0,\\\\\n    \\E[z_{it}\\Delta u_{it}] = 0.\n\\end{aligned}\n\\]\nIn most contexts, one has to look for external variables that can serve as instruments.\nHowever, Equation 4.7 is a very special case where one can use instruments internal to the model!\n\n4.3.1 The Anderson-Hsiao Estimator\nIn particular, consider using \\(y_{it-2}\\) as an instrument.\n\nRelevance seems to be relatively straightforward, as the target endogenous variable \\(\\Delta y_{it-1}= y_{it-1}-y_{it-2}\\) actually has the instrument inside.\nExogeneity can be justified by appealing to sequential exogeneity: \\[ \\E[y_{it-2}\\Delta u_{it}]  = \\E[y_{it-2}u_{it} - y_{it-2}u_{it-1}]=0. \\]\n\nHence \\(y_{it-2}\\) is a valid instrument!\nThe resulting IV estimator is known as the Anderson and Hsiao (1982) estimator and given by \\[\n\\hat{\\lambda}^{AH} = \\dfrac{ \\sum_{t=2}^T y_{it-2}\\Delta y_{it} }{\\sum_{t=2}^T y_{it-2}\\Delta y_{it} }.\n\\]\n\n\n4.3.2 Further Dynamic Panel IV Estimators\nAre there more instruments that can use for \\(\\Delta y_{it-1}\\)? Using more instruments will induce overidentification and potentially lead to more precise estimators, solving one of the key drawbacks of the Anderson and Hsiao (1982) estimator (Arellano 1989).\nAs a partial answer, suppose we consider \\(y_{it-k}\\) for \\(k\\geq 2\\). By applying sequential exogeneity again we can show that \\(y_{it-k}\\) is exogenous: \\[  \n\\E[y_{it-k}\\Delta u_{it}]  = \\E[y_{it-k}u_{it} - y_{it-k}u_{it-1}]=0.\n\\] Provided \\(y_{it-k}\\) is correlated with \\(\\Delta y_{it-1}\\) and available in the data, it also becomes a valid instrument. Following this chain of reasoning and using all available lags \\(y_{it-k}\\) yields the Arellano and Bond (1991) estimator.\nEven further instruments have been found for Equation 4.7 by Ahn and Schmidt (1995) and Blundell and Bond (1998), among others.\nAll of these estimators are implemented in\n\nR: plm.\nPython: pydynpd.\n\n\n\n4.3.3 Properties of Dynamic Panel IV Estimators\nUnder some standard conditions, the above instrumental variable estimators will all be consistent and asymptotically normal for \\(\\lambda\\) as \\(N\\to\\infty\\) and \\(T\\) is fixed. The matter is rather more delicate if both \\(N\\) and \\(T\\) are large, and the above dynamic panel IV estimators offer an interesting and natural example of the many moments bias. See Alvarez and Arellano (2003).",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interlude: Standard Dynamic Panel Estimators</span>"
    ]
  },
  {
    "objectID": "linear/linear-dynamic-panel-iv.html#extra-endogeneity-and-the-within-estimator",
    "href": "linear/linear-dynamic-panel-iv.html#extra-endogeneity-and-the-within-estimator",
    "title": "4  Interlude: Standard Dynamic Panel Estimators",
    "section": "4.4 Extra: Endogeneity and the Within Estimator",
    "text": "4.4 Extra: Endogeneity and the Within Estimator\nOne may think that we had the endogeneity problem (4.8) because we took first differences instead of applying the within transformation.\nHowever, the same issue endogeneity issue affects the within estimator. First, for \\(T=2\\) the above discussion applies directly, as the within transformation is numerically identical to first differencing. Second, more generally, the within estimator will suffer from its own version of endogeneity. To see the issue, note that the within-transformed model (4.6) can be written as (see Equation 3.3): \\[\n    \\tilde{y}_{it} = \\lambda \\tilde{y}_{it-1} + \\tilde{u}_{it}.\n\\]\nOne can now immediately see that \\(\\tilde{y}_{it-1}\\) will also be an endogenous regressor as\n\\[\n    \\E[\\tilde{y}_{it-1}\\tilde{u}_{it}] = \\E\\left[\\left(y_{it-1}- T^{-1}\\sum_{s=0}^{T-1} y_{is} \\right)\\left(u_{it} - T^{-1}\\sum_{r=1}^{T}u_{ir} \\right) \\right].\n\\]\nThe expectation on the right hand side contains “bad” expectations of the form \\(\\E[u_{it}y_{is}]\\) with \\(t&lt;s\\) (recall Equation 4.4).\nWe conclude that for any fixed \\(T\\) the within estimator will also suffer from endogeneity bias. Nickell (1981) shows that it is of the order \\(O(T^{-1})\\). Furthermore, this bias is likely to be large in practice (see Kiviet 1995).\n\n\nNext Section\nNext, we examine how the above “standard” dynamic panel IV estimators break down when individual coefficients vary across observations.\n\n\n\n\nAhn, Seung Chan, and Peter Schmidt. 1995. “Efficient Estimation of Models for Dynamic Panel Data.” Journal of Econometrics 68 (1): 5–27. https://doi.org/10.1016/0304-4076(94)01641-C.\n\n\nAlvarez, Javier, and Manuel Arellano. 2003. “The Time Series and Cross-Section Asymptotics of Dynamic Panel Data Estimators.” Econometrica 71 (4): 1121–59.\n\n\nAnderson, T. W., and Cheng Hsiao. 1982. “Formulation and estimation of dynamic models using panel data.” Journal of Econometrics 18 (1): 47–82. https://doi.org/10.1016/0304-4076(82)90095-1.\n\n\nArellano, Manuel. 1989. “A note on the Anderson-Hsiao estimator for panel data.” Economics Letters 31 (4): 337–41. https://doi.org/10.1016/0165-1765(89)90025-6.\n\n\nArellano, Manuel, and Stephen Bond. 1991. “Some Tests of Specification for Panel Carlo Application to Data: Monte Carlo Evidence and an Application to Employment Equations.” Review of Economic Studies 58: 277–97.\n\n\nBlundell, Richard, and Stephen Bond. 1998. “Initial Conditions and Moment Restrictions in Dynamic Panel Data Models.” Journal of Econometrics 87: 115–43.\n\n\nKiviet, Jan F. 1995. “On Bias, Inconsistency, and Efficiency of Various Estimators in Dynamic Panel Data Models.” Journal of Econometrics 68 (1): 53–78. https://doi.org/10.1016/0304-4076(94)01643-E.\n\n\nNickell, Stephen. 1981. “Biases In Dynamic Models With Fixed Effects.” Econometrica 49 (6): 1417–26.",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interlude: Standard Dynamic Panel Estimators</span>"
    ]
  },
  {
    "objectID": "linear/linear-dynamic-panel-heterogeneity.html",
    "href": "linear/linear-dynamic-panel-heterogeneity.html",
    "title": "5  Heterogeneous Coefficient Dynamic Panels and Instrumental Variable Estimators",
    "section": "",
    "text": "5.1 Introduction and Model\nAs in the static case, it is not clear why the slopes should be homogenous in dynamic models. If the coefficients are the same between units, all units have the same dynamics. Such an assumption seems rather unrealistic in most scenarios.\nAs a consequence, we now consider heterogeneous dynamic models. In this section we will again focus on a simple AR(1) model with no exogenous regressors. Specifically, we will look at the following heterogeneous version of model (4.6): \\[\n\\begin{aligned}\n    y_{it}   & = \\alpha_i +  \\lambda_iy_{it-1} + u_{it}, \\\\\n0 & = \\E[u_{it}| \\curl{y_{is}}_{s\\leq t}] .\n\\end{aligned}\n\\tag{5.1}\\] This model allows for unit-specific dynamics, as the coefficients \\(\\lambda_i\\) can vary across \\(i\\). The above model is also another instance of the general Equation 2.7.\nAs before, we are interested in the average coefficient \\(\\E[\\lambda_i]\\).",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Heterogeneous Coefficient Dynamic Panels and Instrumental Variable Estimators</span>"
    ]
  },
  {
    "objectID": "linear/linear-dynamic-panel-heterogeneity.html#endogeneity-due-to-heterogeneity",
    "href": "linear/linear-dynamic-panel-heterogeneity.html#endogeneity-due-to-heterogeneity",
    "title": "5  Heterogeneous Coefficient Dynamic Panels and Instrumental Variable Estimators",
    "section": "5.2 Endogeneity due to Heterogeneity",
    "text": "5.2 Endogeneity due to Heterogeneity\nCan the IV estimators of the previous section estimate \\(\\E[\\lambda_i]\\) under model (5.1)? Under what conditions? To answer these questions, recall that the IV estimators of the previous section are based on taking first differences in the model and then using lagged values of \\(y_{it}\\) as instruments.\n\n5.2.1 Endogeneity in Differenced Heterogeneous Equation\nTo replicate the procedure, we take differences in Equation 5.1 and write the differenced model as \\[\n\\begin{aligned}\n    \\Delta y_{it} & = \\lambda \\Delta y_{it-1} +  v_{it}, \\\\\n    v_{it} & = \\eta_i\\Delta y_{it-1} + \\Delta u_{it} =0,\n\\end{aligned}\n\\tag{5.2}\\] where we label \\[\n\\begin{aligned}\n\\lambda & = \\E[\\lambda_i], \\\\\n\\eta_i & = \\lambda_i - \\lambda.\n\\end{aligned}\n\\]\nIt is easy to check that \\(\\Delta y_{it-1}\\) is still endogenous because it contains \\(u_{it-1}\\), which is correlated with the residual term. The same problematic term \\(\\lambda \\E[u_{it-1}^2]\\) will be present in \\(\\E[v_{it}\\Delta y_{it-1}]\\).\n\n\n5.2.2 Conditions for Instruments\nCan we find a suitable instrument for \\(\\Delta y_{it-1}\\)? Any valid instrument must satisfy relevance and exogeneity, which now take the following form: \\[\n\\begin{aligned}\n    \\E[z_{it}\\Delta y_{it-1}] &  \\neq 0 ,\\\\\n    \\E[z_{it} v_{it}] & = \\E[ \\eta_i z_{it}\\Delta y_{it-1} ] + \\E[z_{it}u_{it}].\n\\end{aligned}\n\\] Note that a new \\(\\E[ \\eta_i z_{it}\\Delta y_{it-1} ]\\) term now appears in the exogeneity condition.\n\n\n5.2.3 Endogeneity of Lagged Outcomes\nUnlike in the homogeneous case, \\(y_{it-2}\\) is not a valid instrument anymore. We will show that \\(y_{it-2}\\) is not exogenous in a simple case with the following assumptions:\n\n\\(\\abs{\\lambda_i}&lt;1\\).\nEquation 5.1 can be extended infinitely far into the past by recursive substitution, so that \\[\ny_{it} = \\dfrac{\\alpha_i}{1-\\lambda_i} + \\sum_{k=0}^{\\infty} \\lambda_i^k u_{it-k}.\n\\]\n\\(\\curl{u_{it}}_t\\) is an IID sequence with finite second moments, and \\(u_{it}\\) is independent of \\((\\alpha_i, \\lambda_i)\\).\n\nUnder the above assumptions the first expectation in \\(\\E[y_{it-2} v_{it}]\\) can be evaluated as follows: \\[\n\\begin{aligned}\n& \\E[ \\eta_i y_{it-2}\\Delta y_{it-1} ]\n\\\\\n% & = \\E\\left[ \\eta_i\\left( \\left(\\sum_{k=0}^{\\infty} \\lambda_i^k u_{i,t-k-1}\\right)\\left(\\sum_{k=0}^{\\infty} \\lambda_i^k u_{i,t-k-2}\\right) - \\left(\\sum_{k=0}^{\\infty} \\lambda_i^k u_{i,t-k-2}\\right)^2 \\right) \\right] \\\\\n& = \\E\\left[ \\eta_i\\left( \\left(\\sum_{k=0}^{\\infty} \\lambda_i^{1+2k} u_{i,t-k-2}^2 \\right)  -  \\left(\\sum_{k=0}^{\\infty} \\lambda_i^{2k} u^2_{i,t-k-2}\\right)  \\right)\\right] \\\\\n& = \\E[u_{it}^2] \\E\\left[\\eta_i (1-\\lambda_i) \\sum_{k=0}^{\\infty} \\lambda_i^{2k}   \\right].\n\\end{aligned}\n\\] In general, there is no reason to expect the above expectation to be zero if \\(\\eta_i\\) is not zero. The second term involves a sum of even-order moments of \\(\\eta_i\\) (equivalently, \\(\\lambda_i)\\); such a sum would in general be non-zero.\nWe conclude that \\[\n\\E[ \\eta_i y_{it-2}\\Delta y_{it-1} ]\\neq 0,\n\\] and so in general that \\[\n\\E[y_{it-2} v_{it}]\\neq 0.\n\\] In other words, \\(y_{it-2}\\) is not a valid instrument under the heterogeneous model (5.1). The same logic applies under more general assumptions and to higher-order lags of \\(y_{it}\\).\nMore broadly, the problem of finding a valid instrument \\(z_{it}\\) for Equation 5.2 appears intractable. The relevance condition requires that \\(z_{it}\\) be correlated with \\(\\Delta y_{it-1}\\). As a consequence, it is likely that \\(z_{it}\\) will also be correlated with \\(\\eta_i \\Delta y_{it-1}\\) (particularly since \\(\\eta_i\\) appears inside \\(\\Delta y_{it-1}\\)). However, it would then be the case that \\(\\E[ \\eta_i z_{it}\\Delta y_{it-1} ]\\neq 0\\), and exogeneity would fail.\nWe conclude that the IV estimators of the previous section will not consistently estimate \\(\\E[\\lambda_i]\\), no matter how we choose the instruments, regardless the magnitude of \\(T\\). Moreover, the results of Pesaran and Smith (1995) imply that the estimators may converge to any value (not exceeding 1), regardless of the underlying true values of \\(\\E[\\lambda_i]\\).\n\n\n5.2.4 Aside: Regarding Restrictions on Coefficients\nThere is a further point of contrast with the static case. In section 3 we noted that OLS can consistently estimate the average coefficients in a static model if the coefficients \\(\\bbeta_i\\) are (mean) independent of the regressors. We also derived a weaker condition for the consistency of the within estimator.\nHowever, no such independence assumptions are possible in a dynamic model. By construction, the coefficients \\((\\alpha_i, \\lambda_i)\\) are directly embedded in the process for the regressor \\(y_{it-1}\\) through \\[\ny_{it-1} = \\alpha_i + \\lambda_i y_{it-2} + u_{it-2}.\n\\] As a result, \\(y_{it-1}\\) and \\((\\alpha_i, \\lambda_i)\\) cannot be (mean) independent by construction.\n\n\nNext Section\nIn the next section, we will study a simple estimator for \\(\\E[\\bbeta_i]\\) that is robust both to coefficient heterogeneity and dynamics.\n\n\n\n\nPesaran, M. Hashem, and Ron P. Smith. 1995. “Estimating long-run relationships from dynamic heterogeneous panels.” Journal of Econometrics 6061: 473–77.",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Heterogeneous Coefficient Dynamic Panels and Instrumental Variable Estimators</span>"
    ]
  },
  {
    "objectID": "linear/linear-mean-group.html",
    "href": "linear/linear-mean-group.html",
    "title": "6  Mean Group: Robust Estimator for Average Coefficients",
    "section": "",
    "text": "6.1 Mean Group Estimation\nThe results of the previous section and section 3 leave us with key two questions:\nAs it turns out, there is indeed an estimator that is robust both to heterogeneity and dynamics. The mean group (MG) estimator, due to M. H. Pesaran and Smith (1995), permits estimating average coefficients in heterogeneous panels, regardless of the relationship between the coefficients and the covariates. It also does not require strict exogeneity and is compatible with dynamic models. However, this generality comes at a cost: the mean group estimator typically has stricter data requirements compared to non-robust alternatives.",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Mean Group: Robust Estimator for Average Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-mean-group.html#mean-group-estimation",
    "href": "linear/linear-mean-group.html#mean-group-estimation",
    "title": "6  Mean Group: Robust Estimator for Average Coefficients",
    "section": "",
    "text": "In static models, can we estimate the average effect without imposing restrictions on the relationship between \\(\\bx_{it}\\) and \\(\\bbeta_i\\)?\nIn dynamic models, can we estimate \\(\\E[\\lambda_i]\\) at all?\n\n\n\n6.1.1 Model\nTo formally define the mean group estimator, we return to the general Equation 2.7: \\[\n    \\by_{it} = \\bx_{it}'\\bbeta_i + u_{it},\n\\] where we label the dimension of the vectors \\(\\bx_{it}\\) and \\(\\bbeta_i\\) as \\(p\\). We can also express this model in unit-level matrix form by stacking observations across \\(t\\) for each unit \\(i\\): \\[\n\\by_i = \\bX_i\\bbeta_i + \\bu_i,\n\\] where \\(\\bX_i\\) is now a \\(T\\times p\\) matrix of covariates, with \\(T\\) representing the number of observations for each unit.\nIn what follows, we will assume that the regressors \\(\\bx_{it}\\) are orthogonal to the unobserved component \\(u_{it}\\): \\[\n\\E[\\bx_{it}u_{it}] =0.\n\\tag{6.1}\\] This assumption is compatible with both static and dynamic models and is implied by sequential exogeneity.\n\n\n6.1.2 Definition\nFor the mean group estimator to be well-defined, we make two further assumptions:\n\nSufficient unit-level data: each unit must have at least as many observations as regressors, i.e., \\(T\\geq p\\).\nNon-singularity: \\(\\bX_i'\\bX_i\\) has rank maximal rank (\\(p\\)) for all units \\(i\\).\n\nUnder these assumptions, we can compute the OLS estimator of \\(\\bbeta_i\\) for each unit \\(i\\) \\[\n    \\hat{\\bbeta}_i = \\left(\\bX_i'\\bX_i \\right)^{-1}\\bX_i'\\by_i.\n\\tag{6.2}\\]\nThe mean group estimator (M. H. Pesaran and Smith 1995) is defined as the average of unit-level estimators (6.2): \\[\n    \\hat{\\bbeta}_{MG} = \\dfrac{1}{N} \\sum_{i=1}^N \\hat{\\bbeta}_i =  \\dfrac{1}{N} \\sum_{i=1}^N \\left(\\bX_i'\\bX_i \\right)^{-1}\\bX_i'\\by_i.\n\\] In essence, the mean group estimator involves running separate regressions for each unit and averaging the resulting coefficients. The first step requires having enough observations per unit — at least one observation is available for each heterogeneous coefficient.\n\n\n\n\n\n\nWe introduce the MG estimator under the orthogonality condition (6.1). However, it is also possible to introduce an analogous estimator if \\(\\E[\\bx_{it}u_{it}]\\neq 0\\), but instruments for \\(\\bx_{it}\\) are available. In this case, suitable unit-level IV/2SLS estimators replace \\(\\hat{\\bbeta}_i\\) (e.g. Bai, Marcellino, and Kapetanios 2023).\n\n\n\n\n\n6.1.3 Properties\nTo analyze the properties of the \\(\\hat{\\bbeta}_{MG}\\), we can substitute the model for \\(\\by_i\\) into each individual estimator. This substitution yields the sampling error form of the estimator: \\[\n    \\hat{\\bbeta}_{MG}  = \\dfrac{1}{N} \\sum_{i=1}^N \\bbeta_i    + \\dfrac{1}{N} \\sum_{i=1}^N \\left(\\bX_i'\\bX_i \\right)^{-1}\\bX_i'\\bu_i.\n\\]\nAs \\(N\\) grows, the first term will converge to the average effect: \\[\n\\dfrac{1}{N} \\sum_{i=1}^N \\bbeta_i   \\xrightarrow{p} \\E[\\bbeta_i].\n\\] This convergence holds regardless of assumptions on the dependence between \\(\\bbeta_i\\) and \\(\\bX_i\\).\nThe second term’s behavior determines the estimator’s overall properties, depending on whether strict exogeneity holds:\n\nIf strict exogeneity holds, the mean group estimator is unbiased and consistent for \\(\\E[\\bbeta_i]\\) even for \\(T\\) fixed. In this case it directly holds that \\[ \\E\\left[ \\left(\\bX_i'\\bX_i \\right)^{-1}\\bX_i'\\bu_i\\right] =0 \\] for any fixed value of \\(T\\).\nIf the model is dynamic or strict exogeneity fails for any other reason, the mean group estimator will typically only be consistent as both \\(N, T\\to\\infty\\). In this case it may be that \\[ \\E\\left[ \\left(\\bX_i'\\bX_i \\right)^{-1}\\bX_i'\\bu_i\\right] \\neq 0 ,\\] and \\(\\hat{\\bbeta}_{MG}\\) will be biased for any given finite \\(T\\). However, under standard assumptions that limit dependence across \\(t\\), this bias will typically be of the order \\(O(T^{-1})\\) and vanish as \\(T\\to\\infty\\).",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Mean Group: Robust Estimator for Average Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-mean-group.html#comparing-estimators",
    "href": "linear/linear-mean-group.html#comparing-estimators",
    "title": "6  Mean Group: Robust Estimator for Average Coefficients",
    "section": "6.2 Comparing Estimators",
    "text": "6.2 Comparing Estimators\n\n6.2.1 Conditions for Consistency\nWe now have have two estimation strategies per case. For the strictly exogenous case, we have within and mean group estimation. In the dynamic case, we can use dynamic panel IV estimators or again use the mean group estimators.\nThe following tables summarize and contrast the requirements for each estimation strategy to consistently estimate \\(\\E[\\bbeta_i]\\):\n\nStrict exogeneityDynamic model with \\(k\\) lags\n\n\n\n\n\n\n\n\n\n\n\nWithin\nMG\n\n\n\n\nData requirements\n\\(T \\geq 2\\)\n\\(T \\geq p\\)\n\n\nAssumptions on \\((\\beta_i, X_i)\\)\n\\(\\mathbb{E}[\\tilde{X}_i'\\tilde{X}_i\\eta_i]=0\\)\nNone\n\n\nAsymptotic framework\nFixed-\\(T\\)\nFixed-\\(T\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIV\nMG\n\n\n\n\nData requirements\n\\(T \\geq k+2\\)\n\\(T \\geq p+k\\)\n\n\nAssumptions on \\((\\beta_i, X_i)\\)\nNo consistency\nNone\n\n\nAsymptotic framework\nNo consistency\nLarge-\\((N, T)\\)\n\n\n\n\n\n\n\n\n6.2.2 Efficiency\nWhile the mean group estimator provides robustness to heterogeneity and dynamics, it is generally less efficient than alternative estimators when those alternatives are consistent. This loss of efficiency directly follows from the AM-HM inequality and is well-documented(H. Pesaran, Smith, and Im 1996; M. H. Pesaran, Shin, and Smith 1999; Hsiao, Pesaran, and Tahmiscioglu 1999).\nHowever, one might argue that this loss of efficiency is irrelevant, as the conditions for the consistency of alternatives require unrealistic restrictions on the coefficients. Still, there are some ways of obtaining a more efficient robust estimator, such as applying a Mundlak device, see Breitung and Salish (2021).",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Mean Group: Robust Estimator for Average Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-mean-group.html#addressing-rank-deficiency",
    "href": "linear/linear-mean-group.html#addressing-rank-deficiency",
    "title": "6  Mean Group: Robust Estimator for Average Coefficients",
    "section": "6.3 Addressing Rank Deficiency",
    "text": "6.3 Addressing Rank Deficiency\nBefore moving beyond \\(\\E[\\bbeta_i]\\), we return to the assumption that \\(\\bX_i'\\bX_i\\) is non-singular for all units \\(i\\). This requirement might not hold, in particular if \\(T\\) is only slightly larger than \\(p\\) and the model includes discrete regressors. In these cases, it is more likely that there exist units with insufficient individual variation.\nIf such a situation occurs in practice, a common solution is to drop the units with non-invertible \\(\\bX_i'\\bX_i\\). The mean group estimator is computed as an average over the remaining units. Formally, the corresponding mean group estimator is defined as \\[\n    \\hat{\\bbeta}_{MG}^+  = \\dfrac{1}{\\sum_{i=1}^N \\I\\curl{\\det(\\bX_i'\\bX_i)&gt;0} } \\sum_{i=1}^N \\I\\curl{\\det(\\bX_i'\\bX_i)&gt;0} \\hat{\\bbeta}_i.\n\\] Every unit is checked to see if \\(\\det(\\bX_i'\\bX_i)&gt;0\\). If it is, their \\(\\hat{\\bbeta}_i\\) is computed and added to the average.\nWhat does this modified estimator estimate? For simplicity, suppose that \\(\\E[\\bu_i|\\bX_i]=0\\). Then, as \\(N\\to\\infty\\), \\(\\hat{\\bbeta}_{MG}^+\\) converges to the average for the units that have enough variation in their data: \\[\n    \\hat{\\bbeta}_{MG}^+ \\to \\E\\left[\\bbeta_i| \\I\\curl{\\det(\\bX_i'\\bX_i)&gt;0}  \\right].\n\\] This limit may be viewed as an average treatment effect of the treated.\n\n\nNext Section\nIn the next section, we move beyond \\(\\E[\\bbeta_i]\\) and discuss identification of the variance of \\(\\bbeta_i\\).\n\n\n\n\nBai, Yu, Massimiliano Marcellino, and George Kapetanios. 2023. “Mean Group Instrumental Variable Estimation of Time-varying Large Heterogeneous Panels With Endogenous Regressors.” Econometrics and Statistics, June, S2452306223000412. https://doi.org/10.1016/j.ecosta.2023.06.004.\n\n\nBreitung, Jörg, and Nazarii Salish. 2021. “Estimation of Heterogeneous Panels with Systematic Slope Variations.” Journal of Econometrics 220 (2): 399–415. https://doi.org/10.1016/j.jeconom.2020.04.007.\n\n\nHsiao, Cheng, M. Hashem Pesaran, and A. Kamil Tahmiscioglu. 1999. “Bayes Estimation of Short-Run Coefficients in Dynamic Panel Data Models.” In Analysis of Panels and Limited Dependent Variable Models, 268–96. https://doi.org/10.1017/cbo9780511493140.013.\n\n\nPesaran, Hashem, Ron Smith, and Kyung So Im. 1996. “Dynamic Linear Models for Heterogenous Panels.” In The Econometrics of Panel Data, edited by L. Matyas and P. Sevestre, 145–95. https://doi.org/10.1007/978-94-009-0137-7_8.\n\n\nPesaran, M. Hashem, Yongcheol Shin, and Ron P. Smith. 1999. “Pooled Mean Group Estimation of Dynamic Heterogeneous Panels.” Journal of the American Statistical Association 94 (446): 621–34. https://doi.org/10.1080/01621459.1999.10474156.\n\n\nPesaran, M. Hashem, and Ron P. Smith. 1995. “Estimating long-run relationships from dynamic heterogeneous panels.” Journal of Econometrics 6061: 473–77.",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Mean Group: Robust Estimator for Average Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-coefficient-variance.html",
    "href": "linear/linear-coefficient-variance.html",
    "title": "7  Variance of Heterogeneous Coefficients",
    "section": "",
    "text": "7.1 Beyond Average Coefficients",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variance of Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-coefficient-variance.html#beyond-average-coefficients",
    "href": "linear/linear-coefficient-variance.html#beyond-average-coefficients",
    "title": "7  Variance of Heterogeneous Coefficients",
    "section": "",
    "text": "7.1.1 Potential Objects of Interest\nPreviously, we focused on estimating the average coefficient vector \\(\\E[\\bbeta_i]\\) in our model (2.7): \\[\ny_{it} = \\bx_{it}'\\bbeta_i + u_{it}.\n\\tag{7.1}\\] In particular, Chapter 6 has shown that the mean group estimator can consistently estimate \\(\\E[\\bbeta_i]\\) even without imposing restrictions on the dependence between \\(\\bbeta_i\\) and \\(\\bx_{it}\\).\nAverage effects are informative but limited. They do not capture the full variation in responses across individuals (Heckman, Smith, and Clements (1997)). Other parameters of interest include:\n\nThe moments of \\(\\bbeta\\):\n\nVariance: overall dispersion in effects.\nSkewness: asymmetry in responses.\nHigher moments: shape of the distribution.\n\nThe full distribution and quantiles of \\(\\bbeta_i\\). For example, the distribution may be used to compute what proportion of people benefit vs. how many people are hurt by changes in \\(x_{it}\\).\n\n\n\n7.1.2 Model\nAs it turns out, it is possible to identify such distributional features in the static version of model (7.1) without restricting the dependence structure between \\(\\bbeta_i\\) and \\(\\bx_{it}\\) (Arellano and Bonhomme 2012). In this section we discuss a streamlined version of their results for variance, while Chapter 9 shows how to identify the maximal object of interest — the full distribution.\nSpecifically, we consider model (7.1) under a strict exogeneity condition of the form: \\[\n\\E[u_{it}|\\bbeta_i, \\bX_i] =0\n\\tag{7.2}\\] The number \\(T\\) of unit-level observations is assumed to exceed the number \\(p\\) of covariates. We will treat \\(T\\) as fixed, and consider large-\\(N\\) identification and estimation arguments.\nAs before, the model can be written in unit matrix form as \\[\n\\by_i = \\bX_i\\bbeta_i + \\bu_i.\n\\] We will again assume that \\(\\det(\\bX_i'\\bX_i)&gt;0\\) for all \\(i\\). If this condition does not hold, our results will be about the subpopulation of units with positive determinant, as in Chapter 6.",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variance of Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-coefficient-variance.html#identification",
    "href": "linear/linear-coefficient-variance.html#identification",
    "title": "7  Variance of Heterogeneous Coefficients",
    "section": "7.2 Identification",
    "text": "7.2 Identification\nOur object of interest in this section is the variance-covariance matrix of the coefficients \\(\\bbeta_i\\). Its diagonal terms are the variances of individual coefficients, which show how dispersed the effects are overall. The off-diagonal covariance terms capture whether the effects of different covariates tend to go in the same or contrary directions.\nFormally, the variance-covariance matrix \\(\\var(\\bbeta_i)\\) of the vector \\(\\bbeta_i\\) is given by \\[\n    \\var(\\bbeta_i) = \\E[\\bbeta_i\\bbeta_i'] - \\E[\\bbeta_i]\\E[\\bbeta_i]'.\n\\]\n\n7.2.1 Variance Decomposition\nTo identify \\(\\var(\\bbeta_i)\\), we will first look at the second moments of \\(\\by_i\\). Specifically, we will consider the conditional second moment of \\(\\by_i\\) given \\(\\bX_i=\\bX\\), where \\(\\bX\\) is some potential value of \\(\\bX_i\\) such that \\(\\det(\\bX'\\bX)&gt;0\\) and \\(\\bX\\) lies in the support of \\(\\bX_i\\).\nUsing model (7.1) and condition (7.2), the conditional second moment of \\(\\by_i\\) can be represented as \\[\n\\begin{aligned}\n    &\\E[\\by_i\\by_i'|\\bX_i=\\bX]\\\\\n    & = \\E\\left[ (\\bX_i\\bbeta_i+ \\bu_i)(\\bX_i\\bbeta_i+\\bu_i)'|\\bX_i=\\bX \\right]\\\\\n    & =\\bX \\E\\left[\\bbeta_i\\bbeta_i'|\\bX_i=\\bX \\right]\\bX' + \\E\\left[\\bu_i\\bu_i'|\\bX_i=\\bX \\right].\n\\end{aligned}\n\\tag{7.3}\\]\nThe above expression decomposes the conditional second moment of \\(\\by_i\\) into two components — one corresponding to \\(\\bbeta_i\\) and the other one to \\(\\bu_i\\).\nIn general, we cannot separate the two components of the second moment of \\(\\by\\). To see why, consider Equation 7.3 as a system of linear equations. The unknowns are the components of the symmetric matrices\n\n\\(\\E\\left[\\bbeta_i\\bbeta_i'|\\bX_i=\\bX \\right]\\) — a total of \\(p(p+1)/2\\) unknowns.\n\\(\\E\\left[\\bu_i\\bu_i'|\\bX_i=\\bX \\right]\\) — a total of \\(T(T+1)/2\\) unknowns.\n\nThe system is underdetermined, as there is a total of only \\(T(T+1)/2\\) distinct equations.\nAt heart, the underdeterminacy stems from the fact that the model allows any dynamic structure for \\(\\curl{u_{it}}_{t=1}^T\\). As a consequence, \\(\\E[\\bu_i\\bu_i'|\\bX_i=\\bX]\\) has too many free elements relative to the number of equations.\n\n\n7.2.2 Imposing Structure on the Error Term\nThis issue can be resolved by imposing assumptions on the time series dependence of \\(u_{it}\\). The magnitudes of \\(T\\) and \\(p\\) determine how many restrictions are necessary. After taking out the \\(p(p+1)/2\\) parameters of \\(\\E[\\bbeta_i\\bbeta_i'|\\bX_i=\\bx]\\), we have at most \\(\\left[T(T+1)-p(p+1) \\right]/2\\) equations left. This number is the number of possible free parameters in \\(\\E[\\bu_i\\bu_i'|\\bX_i=\\bX]\\). In the most unfavorable case \\(T=p+1\\), and we can allow only \\(T+1\\) possible parameters in \\(\\E[\\bu_i\\bu_i'|\\bX_i=\\bX]\\).\nVarious assumptions are possible, and Arellano and Bonhomme (2012) explore moving average and autoregressive structures for \\(u_{it}\\). Here, we will consider the simplest case in which \\(u_{it}\\) is conditionally homoskedastic across time (but not necessarily across \\(\\bX\\)) and uncorrelated across \\(t\\): \\[\n\\begin{aligned}\n    \\E[u_{it}^2|\\bX_i=\\bX] & = \\sigma^2(\\bX), \\\\\n    \\E[u_{it}u_{is}|\\bX_i=\\bX] & = 0, \\quad t\\neq s.\n\\end{aligned}\n\\tag{7.4}\\] Under assumption (7.4) it holds that \\[\n\\E\\left[\\bu_i\\bu_i'|\\bX_i=\\bX \\right] = \\sigma^2(\\bX)\\bI_T.\n\\] There is only one unknown parameter in \\(\\E[\\bu_i\\bu_i'|\\bX_i=\\bX]\\)!\n\n\n7.2.3 Variance of Residuals\nWe can identify the unknown \\(\\sigma^2(\\bX)\\) using a standard argument. Let the annihilator matrix associated with \\(\\bX\\) be given by \\[\n    \\bM(\\bX) = \\bI_T-\\bX(\\bX'\\bX)^{-1}\\bX'.\n\\tag{7.5}\\] Recall three key properties that \\(\\bM(\\cdot)\\) possesses \\[\n\\begin{aligned}\n     \\bM(\\bX)\\bX & =0, \\\\\n      \\bM(\\bX)\\bM(\\bX) & =\\bM(\\bX),  \\\\\n       \\bM(\\bX)' & =\\bM(\\bX).\n\\end{aligned}\n\\] Now consider the following second moment of \\(\\bM(\\bX)\\by_i\\) conditional on \\(\\bX_i=\\bX\\): \\[\n\\begin{aligned}\n    & \\E[\\by_i'\\bM(\\bX)'\\bM(\\bX)\\by_i|\\bX_i=\\bX]\\\\\n    &  = \\E[\\bu_i'\\bM(\\bX)\\bu_i|\\bX_i=\\bX] \\\\\n    & = \\E\\left[ \\mathrm{tr}(\\bu_i'\\bM(\\bX)\\bu_i)|\\bX_i=\\bX\\right] \\\\\n    & = \\sigma^2(\\bX)(T-p).\n\\end{aligned}\n\\] The details of the trace argument are standard and can be found in section 4.11 of Hansen (2022).\nWe conclude that \\(\\sigma^2(\\bX)\\) is identified as \\[\n    \\sigma^2(\\bX) = \\dfrac{1}{T-p} \\E[\\by_i'\\bM(\\bX)\\by_i|\\bX_i=\\bX].\n\\]\n\n\n\n\n\n\nNote that it is also possible to solve for variance parameters from Equation 7.3! This approach can be useful when residuals exhibit more general dependence.\n\n\n\n\n\n7.2.4 Variance of Coefficients\nWe are now in a position to identify \\(\\var(\\bbeta_i)\\). In principle, we can solve for \\(\\E[\\bbeta_i\\bbeta_i']\\) by suitably vectorizing the system in Equation 7.3. However, it will be more convenient to go back to the individual estimators (6.2). For brevity, let \\(\\bH_i = (\\bX_i'\\bX_i)^{-1}\\bX_i'\\), so that\n\\[\n\\hat{\\bbeta}_i = (\\bX_i'\\bX_i)^{-1}\\bX_i'\\by_i =  \\bbeta_i + \\bH_i\\bu_i.\n\\] As \\(\\E[\\bbeta_i\\bu_i']=0\\) by condition (7.2), the variance of the individual estimator can be decomposed as \\[\n\\begin{aligned}\n    & \\var(\\hat{\\bbeta}_i) = \\var\\left(\\bbeta_i + \\bH_i\\bu_i \\right)\\\\\n    & = \\var(\\bbeta_i) + \\var(\\bH_i)\\\\\n    %\n    &\n    = \\var(\\bbeta_i) + \\E\\left[\\bH_i\\bu_i\\bu_i'\\bH_i' \\right]\\\\\n    & =   \\var(\\bbeta_i) + \\E\\left[\\E\\left[\\bH_i\\bu_i\\bu_i'\\bH_i'|\\bX_i \\right]\\right]\\\\\n    & =   \\var(\\bbeta_i) + \\E\\left[\\bH_i\\E\\left[\\bu_i\\bu_i'|\\bX_i \\right]\\bH_i'\\right]\\\\\n    & = \\var(\\bbeta_i) + \\E\\left[\\sigma(\\bX_i)\\bH_i\\bH_i'\\right].\n\\end{aligned}\n\\]\nObserve that the variance \\(\\var(\\hat{\\bbeta}_i)\\) of individual estimators \\(\\hat{\\bbeta}_i\\) (not \\(\\bbeta_i\\)!) is identified as \\[\n    \\var(\\hat{\\bbeta}_i) = \\var\\left(   (\\bX_i'\\bX_i)^{-1}\\bX_i\\by_i  \\right).\n\\]\nSubstituting Equation 7.4 and rearranging, we obtain the following explicit expression for \\(\\var(\\bbeta_i)\\): \\[\n\\begin{aligned}  \n     \\var(\\bbeta_i)  &  =   \\var(\\hat{\\bbeta}_i) -   \\E\\left[\\sigma(\\bX_i)\\bH_i\\bH_i'\\right]\\\\\n     & =  \\var\\left(   (\\bX_i'\\bX_i)^{-1}\\bX_i\\by_i  \\right)\\\\\n     & \\quad  -  \\dfrac{1}{T-p}\\E\\left[ \\E[\\by_i'\\bM(\\bX_i)\\by_i|\\bX_i]\\bH_i\\bH_i'\\right].\n\\end{aligned}\n\\tag{7.6}\\] Note that the right-hand side is a function of the distribution of \\((\\by_i, \\bX_i)\\) — hence identification holds.",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variance of Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-coefficient-variance.html#estimation",
    "href": "linear/linear-coefficient-variance.html#estimation",
    "title": "7  Variance of Heterogeneous Coefficients",
    "section": "7.3 Estimation",
    "text": "7.3 Estimation\nTo construct an estimator for \\(\\var(\\bbeta_i)\\) based on Equation 7.6, we replace the population expectations with their sample counterparts. Specifically, \\(\\var(\\hat{\\bbeta}_i)\\) is estimated using the sample variance of the individual estimators: \\[\n\\begin{aligned}\n    \\widehat{\\var(\\hat{\\bbeta}_i) } = \\dfrac{1}{N}\\sum_{i=1}^N \\left( \\hat{\\bbeta}_i - \\hat{\\bbeta}_{MG} \\right)\\left(\\hat{\\bbeta}_i-\\hat{\\bbeta}_{MG} \\right)'.\n\\end{aligned}\n\\] Likewise, we replace the expectation in the second term of Equation 7.6 with a sample average.\nThis process yields an estimator for the variance of \\(\\bbeta\\): \\[\n\\begin{aligned}\n    \\widehat{\\var(\\bbeta_i) } & = \\dfrac{1}{N}\\sum_{i=1}^N \\left( \\hat{\\bbeta}_i - \\hat{\\bbeta}_{MG} \\right)\\left(\\hat{\\bbeta}_i-\\hat{\\bbeta}_{MG} \\right)'\\\\\n    & \\quad - \\dfrac{1}{(T-p)N}\\sum_{i=1}^N \\by_i'\\bM(\\bX_i)\\by_i\\bH_i\\bH_i'.\n\\end{aligned}\n\\] Under standard regularity conditions, \\(\\widehat{\\var(\\bbeta_i) }\\) is consistent and (with some extra work) asymptotically normal, enabling inference on the variance of \\(\\bbeta_i\\).",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variance of Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-coefficient-variance.html#higher-order-moments-and-moving-beyond",
    "href": "linear/linear-coefficient-variance.html#higher-order-moments-and-moving-beyond",
    "title": "7  Variance of Heterogeneous Coefficients",
    "section": "7.4 Higher-Order Moments and Moving Beyond",
    "text": "7.4 Higher-Order Moments and Moving Beyond\nIt turns out that a similar strategy can be used to identify the third and higher-order moments of \\(\\bbeta_i\\). see Arellano and Bonhomme (2012) for the details. The key ingredients of the identification argument for the \\(k\\)th moments of \\(\\bbeta_i\\) are:\n\n\\(k\\)th moments (or cumulants) of \\(\\by_i\\) and \\(\\hat{\\bbeta}_i\\)\nRestrictions on the time series dynamics of \\(\\curl{u_{it}}_{t=1}^T\\)\nMultiplicative separability of the moments of \\(\\bbeta_i\\) and \\(\\bu_i\\) up to order \\(k\\).\n\nHowever, moments of \\(\\bbeta_i\\) may be also be obtained from the full distribution of \\(\\bbeta_i\\). Moreover, the distribution may also be used to compute quantile of \\(\\bbeta_i\\) and further policy-relevant parameter. As such, this distribution is our maximal object of interest, and we now turn towards its identification.\n\n\nNext Section\nIn the next section, we will review characteristic functions and deconvolution — key ingredients used in identification in the distribution of \\(\\bbeta_i\\).\n\n\n\n\nArellano, Manuel, and Stéphane Bonhomme. 2012. “Identifying distributional characteristics in random coefficients panel data models.” Review of Economic Studies 79 (3): 987–1020. https://doi.org/10.1093/restud/rdr045.\n\n\nHansen, Bruce. 2022. Econometrics. Princeton University Press.\n\n\nHeckman, James J., Jeffrey Smith, and Nancy Clements. 1997. “Making the Most out of Programme Evaluations and Social Experiments : Accounting for Heterogeneity in Programme Impacts.” Review of Economic Studies 64 (4): 487–535. https://doi.org/10.2307/2971729.",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variance of Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-chf.html",
    "href": "linear/linear-chf.html",
    "title": "8  Interlude: Characteristic Functions and Deconvolution",
    "section": "",
    "text": "8.1 Characteristic Functions\nTo discuss the identification of the full distribution of the coefficients \\(\\bbeta_i\\) in model (2.7), we need to review two key concepts: characteristic functions and the deconvolution approach. This brief section can be freely skipped if you are familiar with both.\nIf \\(\\bV\\) is a random \\(T\\)-vector, then the characteristic function \\(\\varphi_{\\bV}(s): \\R^T\\to \\C\\) of \\(\\bV\\) is defined as follows: \\[\n\\varphi_{\\bV}(\\bs) = \\E[\\exp(i\\bs'\\bV)].\n\\] See Durrett (2019) (or your favorite probability textbook) regarding general properties of characteristic functions.\nFor our purposes, we will need the following three key properties:\nConditional characteristic functions may be defined analogously using conditional expectations in place of unconditional ones.",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Interlude: Characteristic Functions and Deconvolution</span>"
    ]
  },
  {
    "objectID": "linear/linear-chf.html#characteristic-functions",
    "href": "linear/linear-chf.html#characteristic-functions",
    "title": "8  Interlude: Characteristic Functions and Deconvolution",
    "section": "",
    "text": "The characteristic function uniquely determines the distribution.\nLet \\(\\bV, \\bU\\) be two independent random vectors. Then the characteristic function of their sum \\(\\bV+\\bU\\) is equal to the product of characteristic function of \\(\\bV\\) and \\(\\bU\\): \\[\n\\begin{aligned}\n     \\varphi_{\\bV+\\bU}(\\bs) & =  \\E\\left[e^{i\\bs'(\\bV+\\bU)}\\right] = \\E\\left[e^{i\\bs'\\bV}e^{i\\bs'\\bU} \\right]\\\\\n     & = \\E\\left[e^{i\\bs'\\bV}\\right]\\E\\left[e^{i\\bs'\\bU}\\right]\\\\\n     &  =  \\varphi_{\\bV}(\\bs) \\varphi_{\\bU}(\\bs).\n\\end{aligned}\n\\tag{8.1}\\]\nLet \\(\\bbeta\\) be a random \\(p\\)-vector and \\(\\bX\\) a matrix. Then \\[\n\\begin{aligned}\n     \\varphi_{\\bX\\bbeta}(\\bs) & = \\E\\left[\\exp(i\\bs'(\\bX\\bbeta)) \\right] \\\\\n     & = \\E\\left[\\exp(i(\\bX'\\bs)'\\bbeta) \\right]\\\\\n     &  = \\varphi_{\\bbeta}(\\bX'\\bs)\n\\end{aligned}\n\\tag{8.2}\\]",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Interlude: Characteristic Functions and Deconvolution</span>"
    ]
  },
  {
    "objectID": "linear/linear-chf.html#deconvolution",
    "href": "linear/linear-chf.html#deconvolution",
    "title": "8  Interlude: Characteristic Functions and Deconvolution",
    "section": "8.2 Deconvolution",
    "text": "8.2 Deconvolution\nProperty (8.1) is particularly useful for statistical applications. It forms the basis of an estimation and identification approach known as deconvolution. This approach will help us identify the distribution of the coefficients \\(\\bbeta_i\\) in the next section.\nAt heart, deconvolution is simple. Suppose that we observe a random vector \\(\\bY\\). \\(\\bY\\) is generated as a sum of two independent vector \\(\\bV\\) and \\(\\bU\\). The distribution of \\(\\bU\\) is known, while the distribution of \\(\\bV\\) is the object of interest.\nBy property (8.1) the characteristic function of \\(\\bY\\) satisfies \\[\n    \\varphi_{\\bY}(\\bs)   =  \\varphi_{\\bV}(\\bs) \\varphi_{\\bU}(\\bs).\n\\] If \\(\\varphi_{\\bU}(\\bs)\\neq 0\\), we can divide and rearrange to obtain \\[\n\\varphi_{\\bV}(\\bs) = \\dfrac{\\varphi_{\\bY}(\\bs) }{\\varphi_{\\bU}(\\bs)}\n\\] By assumption, the distributions of \\(\\bY\\) and \\(\\bU\\) are known, and thus \\(\\varphi_{\\bY}(\\bs)\\) and \\(\\varphi_{\\bU}(\\bs)\\) are identified. It follows that the full \\(\\varphi_{\\bV}(\\cdot)\\) is also identified provided \\(\\varphi_{\\bU}(\\bs)\\neq 0\\) for all \\(\\bs\\) (or at least \\(\\varphi_{\\bU}(\\bs)= 0\\) for “not too many” \\(\\bs\\), see Evdokimov and White (2012)). The distribution of \\(\\bV\\) is identified since characteristic functions uniquely identify distributions.\nThis identification strategy is called deconvolution. The name of the procedure stems from the fact that the distribution of \\(\\bY\\) is the convolution of distributions of \\(\\bV\\) and \\(\\bU\\). Extracting the distribution of \\(\\bV\\) from the laws of \\(\\bY, \\bU\\) may be viewed as an inverse operation.\nObserve that the argument is nonparametric, as it imposes no parametric form assumptions on the distributions involved.\n\n\n\n\n\n\nIt is possible to relax the assumption that the distribution of \\(\\bU\\) is known by using mulitple observations. We will see one approach in the following section. Another approach uses a second observation of \\(\\bY\\) using a result called Kotlarski’s lemma (Kotlarski 1967) (see Evdokimov and White (2012), Lewbel (2022) for extensions). Used with measurement error (see a review in Schennach 2016), nonparametric panel data models (Evdokimov 2010), and identification of systems of simultaneous equations (Lewbel, Schennach, and Zhang 2024).\n\n\n\n\n\nNext Section\nIn the next section, we will discuss identification of the distribution of the coefficients \\(\\bbeta_i\\) in model (2.7) using the tools of this section.\n\n\n\n\nDurrett, Rick. 2019. Probability: Theory and Examples. Cambridge University Press. https://doi.org/10.1017/9781108591034.\n\n\nEvdokimov, Kirill. 2010. “Identification and Estimation of a Nonparametric Panel Data Model with Unobserved Heterogeneity.”\n\n\nEvdokimov, Kirill, and Halbert White. 2012. “Some Extensions of a Lemma of Kotlarski.” Econometric Theory 28 (4): 925–32. https://doi.org/10.1017/S0266466611000831.\n\n\nKotlarski, Ignacy. 1967. “On Characterizing the Gamma and the Normal Distribution.” Pacific Journal of Mathematics 20 (1): 69–76. https://doi.org/10.2140/pjm.1967.20.69.\n\n\nLewbel, Arthur. 2022. “Kotlarski with a Factor Loading.” Journal of Econometrics 229 (1): 176–79. https://doi.org/10.1016/j.jeconom.2020.12.012.\n\n\nLewbel, Arthur, Susanne M. Schennach, and Linqi Zhang. 2024. “Identification of a Triangular Two Equation System Without Instruments.” Journal of Business & Economic Statistics 42 (1): 14–25. https://doi.org/10.1080/07350015.2023.2166052.\n\n\nSchennach, Susanne M. 2016. “Recent Advances in the Measurement Error Literature.” Annual Review of Economics 8 (1): 341–77. https://doi.org/10.1146/annurev-economics-080315-015058.",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Interlude: Characteristic Functions and Deconvolution</span>"
    ]
  },
  {
    "objectID": "linear/linear-distribution.html",
    "href": "linear/linear-distribution.html",
    "title": "9  Distribution of Heterogeneous Coefficients",
    "section": "",
    "text": "9.1 Model and Conditional Independence Assumption",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Distribution of Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-distribution.html#model-and-conditional-independence-assumption",
    "href": "linear/linear-distribution.html#model-and-conditional-independence-assumption",
    "title": "9  Distribution of Heterogeneous Coefficients",
    "section": "",
    "text": "9.1.1 Model\nWe are now in a position to obtain our final and strongest result in this block: identify the full distribution of \\(\\bbeta_i\\) in model (2.7): \\[\ny_{it} = \\bbeta_i'\\bx_{it} + u_{it}.\n\\] As in Chapter 7, we impose strict exogeneity \\[\n\\E[\\bu_i|\\bbeta_i, \\bX_i] = 0.\n\\] We also assume the existence of the first two moments of \\(\\bbeta_i, \\bX_i\\), and \\(\\bu_i\\).\nAs before, the number \\(T\\) of unit-level observations is assumed to exceed the number \\(p\\) of covariates. We treat \\(T\\) as fixed, and consider large-\\(N\\) identification and estimation arguments.\n\n\n9.1.2 Conditional Independence of \\(\\bbeta_i\\) and \\(\\bu_i\\)\nThe key to our identification strategy is the following assumption of conditional independence between \\(\\bbeta_i\\) and \\(\\bu_i\\): \\[\n\\bbeta_i \\independent \\curl{u_{it}}_{t=1}^T |\\bX\n\\tag{9.1}\\] To understand assumption (9.1), consider a production function example. Let \\(u_{it}\\) be the measurement error in the output value \\(y_{it}\\). The variance of \\(u_{it}​\\) may depend on the scale of the firm (captured by capital), leading to dependence between \\(\\bX_i\\) and \\(\\bu_i\\). However, it is plausible that the firm size captures all information about firm technology relevant for measurement error. In this case, the assumption appears reasonable.\n\n\n9.1.3 Implication of Conditional Independence\nGiven the conditional independence assumption (9.1), both \\(\\by_i\\) and the individual estimators \\(\\hat{\\bbeta}_i\\) are sums of two conditionally independent vectors. Specifically, conditionally on \\(\\curl{\\bX_i=\\bX}\\):\n\n\\(\\by_i\\) is the sum of \\(\\bX\\bbeta_i\\) and \\(\\bu_i\\)\n\\(\\hat{\\bbeta}_i\\) is the sum of \\(\\bbeta_i\\) and \\((\\bX'\\bX)^{-1}\\bX\\bu_i\\)\n\nWe can write the conditional characteristic function of \\(\\by_i\\) given \\(\\bX_i=\\bX\\) using properties (8.1) and (8.2) as: \\[\n\\begin{aligned}\n    \\varphi_{\\by_i|\\bX_i}(\\bs|\\bX) & = \\varphi_{\\bX'\\bbeta_i|\\bX_i}(\\bs|\\bX)\\varphi_{\\bu_i|\\bX_i}(\\bs|\\bX) \\\\\n    & = \\varphi_{\\bbeta_i|\\bX_i}(\\bX'\\bs|\\bX)\\varphi_{\\bu_i|\\bX_i}(\\bs|\\bX).\n\\end{aligned}\n\\tag{9.2}\\] Similarly, the conditional characteristic function of \\(\\hat{\\bbeta}_i\\) given \\(\\bX_i=\\bX\\) satisfies \\[\n\\begin{aligned}\n    \\varphi_{\\hat{\\bbeta}_i|\\bX_i}(\\bs|\\bX) & = \\varphi_{\\bbeta_i|\\bX_i}(\\bs|\\bX) \\varphi_{\\bH_i\\bu_i|\\bX_i}(\\bs|\\bX) \\\\\n    &  = \\varphi_{\\bbeta_i|\\bX_i}(\\bs|\\bX) \\varphi_{\\bu_i|\\bX_i}(\\bX(\\bX'\\bX)^{-1}\\bs|\\bX),\n\\end{aligned}\n\\tag{9.3}\\] where we again define \\(\\bH_i = (\\bX_i'\\bX_i)^{-1}\\bX_i\\).",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Distribution of Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-distribution.html#identification-of-the-distribution",
    "href": "linear/linear-distribution.html#identification-of-the-distribution",
    "title": "9  Distribution of Heterogeneous Coefficients",
    "section": "9.2 Identification of the Distribution",
    "text": "9.2 Identification of the Distribution\n\n9.2.1 Overall Strategy\nTo identify the distribution, it is sufficient to identify the conditional characteristic function \\(\\varphi_{\\bbeta_i|\\bX_i}(\\bs|\\bX)\\) for all \\(\\bX\\) in the support of \\(\\bX_i\\). We will proceed similarly to how we identified the variance. The steps are:\n\nIdentify \\(\\varphi_{\\bu_i|\\bX_i}(\\cdot|\\bX)\\) from Equation 9.2.\nApply deconvolution to Equation 9.3 to recover \\(\\varphi_{\\bbeta_i|\\bX_i}(\\bs|\\bX)\\).\nInvert the characteristic function of \\(\\bbeta_i\\) to obtain the distribution.\n\n\n\n9.2.2 Equation in Hessians of Characteristic Functions\nWe start by rewriting Equation 9.2 in a more useful form. The characteristic functions in (9.2) are twice differentiable under our moment assumptions. Taking logarithms (see here) and differentiating twice yields \\[\n\\begin{aligned}\n    & \\dfrac{\\partial^2 \\log(   \\varphi_{\\by_i|\\bX_i}(\\bs|\\bX))}{\\partial\\bs\\partial\\bs'} \\\\\n    & = \\bX \\dfrac{\\partial^2 \\log( \\varphi_{\\bbeta_i|\\bX_i}(\\bX'\\bs|\\bX)) }{\\partial \\bs\\partial\\bs'} \\bX' +  \\dfrac{\\partial^2 \\log(\\varphi_{\\bu_i|\\bX_i}(\\bs|\\bX))}{\\partial \\bs\\partial\\bs'} .\n\\end{aligned}\n\\tag{9.4}\\]\nThis equation is similar to the expression (7.3) we obtained for variance. It decomposes the characteristic function of the data into contributions from the coefficients \\(\\bbeta_i\\) and the residuals \\(\\bu_i\\). Unlike the variance expression, system (9.4) is a functional equation parametrized by \\(\\bs\\).\n\n\n9.2.3 Imposing Structure on the Error Term\nOur goal is to solve for the second term in the linear system (9.4). However, like system (7.3), system (9.4) is underdetermined. Accordingly, we need to impose additional assumptions to disentangle the \\(\\bu_i\\) component from the \\(\\bbeta_i\\) one.\nIn these notes, we consider a simple assumption that strengthens our temporal homoskedasticity assumption (7.4). Specifically, we will assume that \\(u_{it}\\) is IID across \\(i\\) and \\(t\\) conditional on \\(\\bX_i=\\bX\\). This assumption implies that all \\(u_{it}\\) have the same characteristic function for all \\(i\\) and \\(t\\): \\[\n    \\varphi_{u_{i1}|\\bX_i}(s|\\bX) = \\cdots = \\varphi_{u_{iT}|\\bX_i}(s|\\bX).\n\\tag{9.5}\\] We label the common function \\(\\varphi_{u|\\bX_i}(s|\\bX)\\).\nThe characteristic function of the \\(T\\)-vector \\(\\bu_i\\) can be written as \\[\n\\begin{aligned}\n    \\varphi_{\\bu_i|\\bX_i}(\\bs|\\bX) & = \\prod_{j=1}^T \\varphi_{u|\\bX_i}(s_j|\\bX), \\\\\n    \\bs & = (s_1, s_2, \\dots, s_T).\n\\end{aligned}\n\\] Taking logarithms turns the product into a sum: \\[\n    \\log\\left(\\varphi_{\\bu_i|\\bX_i}(\\bs|\\bX)\\right) = \\sum_{j=1}^T \\log(\\varphi_{u|\\bX_i}(s_j|\\bX)).\n\\] The Hessian of this function with respect to \\(\\bs\\) is diagonal: \\[\n\\begin{aligned}\n    \\dfrac{\\partial^2 \\log(\\varphi_{\\bu_i|\\bX_i}(\\bs|\\bX))}{\\partial \\bs\\partial\\bs'}  & = \\diag\\curl{\\bphi(\\bs)},\\\\\n\\end{aligned}\n\\] where \\[\n    \\bphi(\\bs)  =  \\left(\\dfrac{d^2\\log(\\varphi_{u|\\bX_i}(s_1|\\bX))}{ds_1^2}, \\dots,   \\dfrac{d^2\\log(\\varphi_{u|\\bX_i}(s_T|\\bX))}{ds_T^2}\\right).\n\\] To summarize, assumption (9.5) reduces the unknown \\(T\\times T\\) matrix \\(\\frac{\\partial^2 \\log(\\varphi_{\\bu_i|\\bX_i}(\\bs|\\bX))}{\\partial \\bs\\partial\\bs'}\\) to an unknown \\(T\\)-vector \\(\\bphi(\\bs)\\). There are now sufficiently many equations to cover all the remaining unknown components, provided standard rank conditions hold.\n\n\n9.2.4 Solving for the Distribution of Residuals\nTo solve for \\(\\bphi(\\bs)\\), we return to (9.4). We first put it into more familiar tall form (one line, one equation) using the vectorization operator. Applying the vectorization operator yields \\[\n\\begin{aligned}\n    & \\vecc\\left(\\dfrac{\\partial^2 \\log(    \\varphi_{\\by_i|\\bX_i}(\\bs|\\bX))}{\\partial\\bs\\partial\\bs'}\\right) \\\\\n    &  = (\\bX \\otimes \\bX) \\vecc\\left(\\dfrac{\\partial^2 \\log( \\varphi_{\\bbeta_i|\\bX_i}(\\bX'\\bs|\\bX)) }{\\partial \\bs\\partial\\bs'}\\right) +   \\bA\\bphi(\\bs),\n\\end{aligned}\n\\tag{9.6}\\] where an explicit formula for \\(\\bA\\) can be found here.\nNow we premultiply system (9.6) by \\(\\bM(\\bX\\otimes \\bX)\\) where \\(\\bM(\\cdot)\\) is defined in (7.5): \\[\n\\begin{aligned}\n    & \\bM(\\bX\\otimes \\bX)   \\vecc\\left(\\dfrac{\\partial^2 \\log(  \\varphi_{\\by_i|\\bX_i}(\\bs|\\bX))}{\\partial\\bs\\partial\\bs'}\\right)\n    \\\\ & = \\bM(\\bX\\otimes \\bX)\\bA\\bphi(\\bs)\n\\end{aligned}\n\\tag{9.7}\\] We can solve this system for \\(\\bphi(\\bs)\\) provided \\(\\rank(\\bM(\\bX\\otimes \\bX)\\bA)=T\\). Indeed, this rank condition holds in this case, as shown by Arellano and Bonhomme (2012). As both \\(\\bM(\\bX\\otimes\\bX)\\) and \\(\\varphi_{\\by_i|\\bX_i}(\\cdot|\\cdot)\\) are identified, we conclude that \\(\\bphi(\\bs)\\) is also identified.\nThe characteristic function of \\(\\bu_i\\) is now straighforward to recover from \\(\\bphi(\\bs)\\) by integrating twice with respect to \\(\\bs\\). As \\(\\bphi(\\bs)\\) encodes second derivatives, we need two initial values. These initial values are provided by the properties of the characteristic function and the assumption of strict exogeneity: \\[\n\\begin{aligned}\n    \\dfrac{\\partial \\log(\\varphi_{\\bu_i|\\bX_i}(0|\\bX))}{\\partial\\bs'} &  = \\E[\\bu_i|\\bX_i=\\bX] = 0,\\\\\n    \\log(\\varphi_{\\bu_i|\\bX_i}(0|\\bX))  & = 0.\n\\end{aligned}\n\\] This completes the first identification step.\n\n\n9.2.5 Identifying the Distribution of Coefficients\nFor the second step — identification of \\(\\varphi_{\\bbeta_i|\\bX_i}\\) — we return to Equation 9.3. We make an additional assumption: \\[\n\\varphi_{\\bu_i|\\bX_i}(\\bs|\\bX)\\neq 0 \\text{ for all }\\bs.\n\\] This assumption allows us to divide by the characteristic function of \\(\\bu_i\\) in Equation 9.3 and obtain \\[\n\\varphi_{\\bbeta_i|\\bX_i}(\\bs|\\bX) = \\dfrac{\\varphi_{\\hat{\\bbeta}_i|\\bX_i}(\\bs|\\bX)  }{\\varphi_{\\bu_i|\\bX_i}(\\bX(\\bX'\\bX)^{-1}\\bs|\\bX)}.\n\\tag{9.8}\\]\nFinally, the density or cumulative distribution functions of the coefficients may be recovered using inversion formulae. For continuously distributed coefficients, the conditional density is: \\[\nf_{\\bbeta_i|\\bX_i}(\\bb|\\bX) = \\dfrac{1}{(2\\pi)^n} \\int_{\\R^p} \\exp(-i\\bs'\\bb)\\varphi_{\\bbeta_i|\\bX_i}(\\bs|\\bX)d\\bs.\n\\] Last, we can recover the unconditional distribution of the coefficients since we know the marginal distribution of \\(\\bX_i\\). For example, if \\(f_{\\bX_i}\\) is the marginal density, the unconditional density of \\(\\bbeta_i\\) is obtained by simply integrating \\(\\bX_i\\) out as \\[\nf_{\\bbeta_i}(\\bb) = \\int f_{\\bbeta_i|\\bX_i}(\\bb|\\bX)f_{\\bX_i}(\\bX)d\\bX.\n\\]",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Distribution of Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "linear/linear-distribution.html#estimation",
    "href": "linear/linear-distribution.html#estimation",
    "title": "9  Distribution of Heterogeneous Coefficients",
    "section": "9.3 Estimation",
    "text": "9.3 Estimation\n\n9.3.1 With Discrete Covariates\nFor estimation, we discuss the conceptually simpler case where \\(\\bX_i\\) has finite support. In such a setting, there is a non-zero probability that \\(\\bX_i\\) takes each possible value.\nEstimation proceeds in three steps:\n\nEstimation of \\(\\varphi_{\\hat{\\bbeta}_i|\\bX_i}(\\cdot|\\bX)\\).\nEstimation of \\(\\varphi_{\\bu_i|\\bX_i}(\\cdot|\\bX)\\).\nCombining the estimators of the first two steps using Equation 9.8 and inverting the resulting estimated characteristic function.\n\nThe characteristic function of the individual estimators \\(\\hat{\\bbeta}_i\\) can then be estimated with the empirical characteristic function on the sample of units with \\(\\bX_i=\\bX\\): \\[\n\\hat{\\varphi}_{\\hat{\\bbeta}_i|\\bX_i}(\\bs|\\bX) = \\dfrac{1 }{\\sum_{i=1}^N \\I\\curl{\\bX_i=\\bX} }\\sum_{i=1}^N \\I\\curl{\\bX_i=\\bX} \\exp\\left( i\\bs'\\hat{\\bbeta}_i \\right).\n\\]\nAs for the characteristic function of \\(\\bu_i\\), it can be estimated from a sample version of Equation 9.7. We replace the characteristic function of the data with its empirical counterpart: \\[\n\\hat{\\varphi}_{\\by_i|\\bX_i}(\\bs|\\bX) = \\dfrac{1 }{\\sum_{i=1}^N \\I\\curl{\\bX_i=\\bX} }\\sum_{i=1}^N \\I\\curl{\\bX_i=\\bX} \\exp\\left( i\\bs'\\by_i \\right).\n\\]\n\n\n9.3.2 With Continuous Covariates\nIf \\(\\bX_i\\) is continuously distributed, it instead necessary estimate the characteristic functions using techniques such as kernel regression. Evdokimov (2010) studies such conditional deconvolution estimators and their asymptotic properties. Inference may be conducted using the results of Kato, Sasaki, and Ura (2021).\n\n\n\n\n\n\nSuch nonparametric estimators may perform poorly due to the curse of dimensionality if \\(T\\) and \\(p\\) are not small. In the next block we will discuss some assumptions that can reduce the dimensionality of the problem and be applied in this context.\n\n\n\n\n\nNext Section\nIn the next section, we briefly conclude the block and discuss some further results on heterogeneous linear models.\n\n\n\n\nArellano, Manuel, and Stéphane Bonhomme. 2012. “Identifying distributional characteristics in random coefficients panel data models.” Review of Economic Studies 79 (3): 987–1020. https://doi.org/10.1093/restud/rdr045.\n\n\nEvdokimov, Kirill. 2010. “Identification and Estimation of a Nonparametric Panel Data Model with Unobserved Heterogeneity.”\n\n\nKato, Kengo, Yuya Sasaki, and Takuya Ura. 2021. “Robust Inference in Deconvolution.” Quantitative Economics 12 (1): 109–42. https://doi.org/10.3982/QE1643.",
    "crumbs": [
      "Linear Models",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Distribution of Heterogeneous Coefficients</span>"
    ]
  },
  {
    "objectID": "references/references.html",
    "href": "references/references.html",
    "title": "References",
    "section": "",
    "text": "Ahn, Seung Chan, and Peter Schmidt. 1995. “Efficient Estimation of Models for Dynamic Panel\nData.” Journal of Econometrics 68 (1): 5–27. https://doi.org/10.1016/0304-4076(94)01641-C.\n\n\nAlvarez, Javier, and Manuel Arellano. 2003. “The Time Series and Cross-Section Asymptotics of Dynamic\nPanel Data Estimators.” Econometrica 71 (4):\n1121–59.\n\n\nAnderson, T. W., and Cheng Hsiao. 1982. “Formulation and estimation of dynamic models using panel\ndata.” Journal of Econometrics 18 (1): 47–82. https://doi.org/10.1016/0304-4076(82)90095-1.\n\n\nArellano, Manuel. 1989. “A note on the\nAnderson-Hsiao estimator for panel data.” Economics\nLetters 31 (4): 337–41. https://doi.org/10.1016/0165-1765(89)90025-6.\n\n\nArellano, Manuel, and Stephen Bond. 1991. “Some Tests of Specification for Panel Carlo Application\nto Data: Monte Carlo Evidence and an Application to Employment\nEquations.” Review of Economic Studies 58:\n277–97.\n\n\nArellano, Manuel, and Stéphane Bonhomme. 2012. “Identifying distributional characteristics in random\ncoefficients panel data models.” Review of Economic\nStudies 79 (3): 987–1020. https://doi.org/10.1093/restud/rdr045.\n\n\nBai, Yu, Massimiliano Marcellino, and George Kapetanios. 2023.\n“Mean Group Instrumental Variable Estimation of Time-varying Large Heterogeneous Panels With Endogenous\nRegressors.” Econometrics and Statistics, June,\nS2452306223000412. https://doi.org/10.1016/j.ecosta.2023.06.004.\n\n\nBeran, Rudolf, Andrey Feuerverger, and Peter Hall. 1996. “On Nonparametric Estimation of Intercept and Slope\nDistributions in Random Coefficient Regression.” The\nAnnals of Statistics 24 (6): 2569–92. https://doi.org/10.1214/aos/1032181170.\n\n\nBester, C Alan, and Christian B Hansen. 2016. “Grouped Effects Estimators in Fixed Effects\nModels.” Journal of Econometrics 190 (1):\n197–208. https://doi.org/10.1016/j.jeconom.2012.08.022.\n\n\nBlundell, Richard, and Stephen Bond. 1998. “Initial Conditions and Moment Restrictions in Dynamic\nPanel Data Models.” Journal of Econometrics 87:\n115–43.\n\n\nBonhomme, Stéphane, Thibaut Lamadon, and Elena Manresa. 2022.\n“Discretizing Unobserved Heterogeneity.”\nEconometrica 90 (2): 625–43. https://doi.org/10.3982/ECTA15238.\n\n\nBonhomme, Stéphane, and Elena Manresa. 2015. “Grouped Patterns of Heterogeneity in Panel\nData.” Econometrica 83 (3): 1147–84. https://doi.org/10.3982/ecta11319.\n\n\nBreitung, Jörg, and Nazarii Salish. 2021. “Estimation of Heterogeneous Panels with Systematic Slope\nVariations.” Journal of Econometrics 220 (2):\n399–415. https://doi.org/10.1016/j.jeconom.2020.04.007.\n\n\nBrockwell, Peter J., and Richard A. Davis. 2016. Introduction to\nTime Series and Forecasting. Springer\nTexts in Statistics. Springer International\nPublishing.\n\n\nCampello, Murillo, Antonio F. Galvao, and Ted Juhl. 2019. “Testing for Slope Heterogeneity Bias in Panel Data\nModels.” Journal of Business and Economic\nStatistics 37 (4): 749–60. https://doi.org/10.1080/07350015.2017.1421545.\n\n\nCard, David. 2001. “Estimating the Return to\nSchooling: Progress on Some Persistent Econometric\nProblems.” Econometrica 69 (5): 1127–60. https://doi.org/10.1111/1468-0262.00237.\n\n\nCombes, Pierre Philippe, Gilles Duranton, Laurent Gobillon, Diego Puga,\nand Sébastien Roux. 2012. “The Productivity\nAdvantages of Large Cities: Distinguishing Agglomeration From Firm\nSelection.” Econometrica 80 (6): 2543–94. https://doi.org/10.3982/ecta8442.\n\n\nDurrett, Rick. 2019. Probability: Theory and\nExamples. Cambridge University Press. https://doi.org/10.1017/9781108591034.\n\n\nEvdokimov, Kirill. 2010. “Identification and\nEstimation of a Nonparametric Panel Data Model with Unobserved\nHeterogeneity.”\n\n\nEvdokimov, Kirill, and Halbert White. 2012. “Some Extensions of a Lemma of Kotlarski.”\nEconometric Theory 28 (4): 925–32. https://doi.org/10.1017/S0266466611000831.\n\n\nHansen, Bruce. 2022. Econometrics. Princeton University Press.\n\n\nHeckman, James J., Jeffrey Smith, and Nancy Clements. 1997. “Making the Most out of Programme Evaluations and Social\nExperiments : Accounting for Heterogeneity in Programme\nImpacts.” Review of Economic Studies 64 (4):\n487–535. https://doi.org/10.2307/2971729.\n\n\nHeckman, James, and Edward Vytlacil. 1998. “Instrumental variables methods for the correlated random\ncoefficient model.” Journal of Human Resources 33\n(4): 974–87.\n\n\nHoderlein, Stefan, Jussi Klemelä, and Enno Mammen. 2010. “Analyzing the Random Coefficient Model\nNonparametrically.” Econometric Theory 26 (03):\n804–37. https://doi.org/10.1017/S0266466609990119.\n\n\nHsiao, Cheng, M. Hashem Pesaran, and A. Kamil Tahmiscioglu. 1999.\n“Bayes Estimation of Short-Run Coefficients\nin Dynamic Panel Data Models.” In Analysis of Panels\nand Limited Dependent Variable Models, 268–96. https://doi.org/10.1017/cbo9780511493140.013.\n\n\nKato, Kengo, Yuya Sasaki, and Takuya Ura. 2021. “Robust\nInference in Deconvolution.”\nQuantitative Economics 12 (1): 109–42. https://doi.org/10.3982/QE1643.\n\n\nKiviet, Jan F. 1995. “On Bias, Inconsistency,\nand Efficiency of Various Estimators in Dynamic Panel Data\nModels.” Journal of Econometrics 68 (1): 53–78.\nhttps://doi.org/10.1016/0304-4076(94)01643-E.\n\n\nKotlarski, Ignacy. 1967. “On Characterizing the\nGamma and the Normal Distribution.”\nPacific Journal of Mathematics 20 (1): 69–76. https://doi.org/10.2140/pjm.1967.20.69.\n\n\nLewbel, Arthur. 2022. “Kotlarski with a\nFactor Loading.” Journal of Econometrics 229 (1):\n176–79. https://doi.org/10.1016/j.jeconom.2020.12.012.\n\n\nLewbel, Arthur, Susanne M. Schennach, and Linqi Zhang. 2024.\n“Identification of a Triangular Two Equation System Without\nInstruments.” Journal of Business & Economic\nStatistics 42 (1): 14–25. https://doi.org/10.1080/07350015.2023.2166052.\n\n\nMundlak, Yair. 1961. “Empirical Production Function\nFree of Management Bias.” Journal of Farm\nEconomics 43 (1): 44. https://doi.org/10.2307/1235460.\n\n\nMurtazashvili, Irina, and Jeffrey M. Wooldridge. 2008. “Fixed effects instrumental variables estimation in\ncorrelated random coefficient panel data models.”\nJournal of Econometrics 142 (1): 539–52. https://doi.org/10.1016/j.jeconom.2007.09.001.\n\n\nNickell, Stephen. 1981. “Biases In Dynamic Models With Fixed\nEffects.” Econometrica 49 (6): 1417–26.\n\n\nPesaran, Hashem, Ron Smith, and Kyung So Im. 1996. “Dynamic Linear Models for Heterogenous\nPanels.” In The Econometrics of Panel Data,\nedited by L. Matyas and P. Sevestre, 145–95. https://doi.org/10.1007/978-94-009-0137-7_8.\n\n\nPesaran, M. Hashem, Yongcheol Shin, and Ron P. Smith. 1999. “Pooled Mean Group Estimation of Dynamic Heterogeneous\nPanels.” Journal of the American Statistical\nAssociation 94 (446): 621–34. https://doi.org/10.1080/01621459.1999.10474156.\n\n\nPesaran, M. Hashem, and Ron P. Smith. 1995. “Estimating long-run relationships from dynamic\nheterogeneous panels.” Journal of Econometrics\n6061: 473–77.\n\n\nSchennach, Susanne M. 2016. “Recent Advances in the\nMeasurement Error Literature.” Annual Review of\nEconomics 8 (1): 341–77. https://doi.org/10.1146/annurev-economics-080315-015058.\n\n\nStefanski, Leonard A., and Raymond J. Carroll. 1985. “Covariate Measurement Error in Logistic\nRegression.” The Annals of Statistics 13 (4):\n1335–51. https://doi.org/10.1214/aos/1176349741.\n\n\nSury, Tavneet. 2011. “Selection and\nComparative Advantage in Technology Adoption.”\nEconometrica 79 (1): 159–209. https://doi.org/10.3982/ecta7749.\n\n\nWooldridge, Jeffrey M. 2003. “Fixed Effects\nEstimation of the Population-Averaged Slopes in a Panel Data Random\nCoefficient Model.” Econometric Theory 19:\n411–13. https://doi.org/10+10170S0266466603002081.\n\n\n———. 2005. “Fixed-effects and related\nestimators for correlated random-coefficient and treatment-effect panel\ndata models.” The Review of Economics and\nStatistics 87 (May): 385–90.",
    "crumbs": [
      "References"
    ]
  }
]