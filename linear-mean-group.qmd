# Mean Group: Robust Estimator for Average Coefficients {#sec-linear-mean-group}

::: {.callout-note appearance="simple" icon=false}

## Summary and Learning Outcomes

This section  
By the end of this section, you should be able to:

-  
:::

## Mean Group Estimation

The results of the previous section and section [-@sec-linear-within] leave us with two questions: 

-  In static models, can we estimate the average effect without limiting the relationship between $\bx_{it}$ and $\bbeta_i$?
-  In dynamic models, can we estimate $\E[\lambda_i]$ at all?
  
As it turns out, there is indeed an estimator that is robust both to heterogeneity and dynamics. The *mean group* (MG) estimator, due to @Pesaran1995, permits estimating average coefficients in heterogeneous panels, regardless of the relationship between the coefficients and the covariates. It also does not require strict exogeneity and is compatible with dynamic models. However, there is a price to pay for this generality, as the mean group estimator typically has stricter data requirements than the non-robust alternatives.


### Model

To define the mean group estimator, we go back to the general @eq-lecture_model: 
$$
	\by_{it} = \bx_{it}'\bbeta_i + u_{it},
$$ 
where we label the dimension of the vectors $\bx_{it}$ and $\bbeta_i$ as $p$. We can also write the above model in unit-level matrix form by stacking the observations across $t$ for each unit $i$:
$$
\by_i = \bX_i\bbeta_i + \bu_i,
$$
where $\bX_i$ is now a $T\times p$ matrix of covariates, where $T$ is the number of unit-level observations. 

In what follows, we will assume that the regressors $\bx_{it}$ are orthogonal to the unobserved component $u_{it}$:
$$
\E[\bx_{it}u_{it}] =0.
$$
This assumption is compatible with both static and dynamic models. It is implied by sequential exogeneity. 

### Definition

Now let us make two further assumptions:

1. *Sufficient unit-level data*: $T\geq p$. 
2. *Non-singularity*: $\bX_i'\bX_i$ has rank maximal rank ($p$) for all units $i$. 

Under these assumptions, we can compute the OLS estimator of $\bbeta_i$ for each unit $i$
$$
	\hat{\bbeta}_i = \left(\bX_i'\bX_i \right)^{-1}\bX_i'\by_i.
$$ {#eq-linear-mg-individual-estimator}
 
The mean group estimator [@Pesaran1995] is defined as the average of unit-level estimators [-@eq-linear-mg-individual-estimator]:
$$
	\hat{\bbeta}_{MG} = \dfrac{1}{N} \sum_{i=1}^N \hat{\bbeta}_i =  \dfrac{1}{N} \sum_{i=1}^N \left(\bX_i'\bX_i \right)^{-1}\bX_i'\by_i.
$$



::: {.callout-note appearance="simple" icon=false}
Under . However, it is also possible 
 it also possible to consider the case where $\E[\bx]$. With suitable instrumental variable regressors, (see e.g. @Bai2023MeanGroupInstrumental)
:::
 


### Properties 

To analyze the properties of the $\hat{\bbeta}_{MG}$, we can substitute the model for $\by_i$ into each individual estimator. This substitution yields the sampling error form of the estimator:
$$
	\hat{\bbeta}_{MG}  = \dfrac{1}{N} \sum_{i=1}^N \bbeta_i	   + \dfrac{1}{N} \sum_{i=1}^N \left(\bX_i'\bX_i \right)^{-1}\bX_i'\bu_i.
$$

As $N$ grows, the first term will converge to the average effect:
$$
\dfrac{1}{N} \sum_{i=1}^N \bbeta_i	 \xrightarrow{p} \E[\bbeta_i].
$$
This convergence holds regardless of assumptions on the dependence between $\bbeta_i$ and $\bX_i$. 

Ah the same time, the second term converges to its expected value  $\E\left[ \left(\bX_i'\bX_i \right)^{-1}\bX_i'\bu_i\right]$.  The behavior of this quantity determines the overall properties of $\hat{\bbeta}_{MG}$. This behavior itself depends on whether strict exogeneity holds or not:

- If strict exogeneity holds, then the mean group estimator is unbiased and consistent for $\E[\bbeta_i]$ even for $T$ fixed. Specifically, under strict exogeneity  it directly holds that $$ \E\left[ \left(\bX_i'\bX_i \right)^{-1}\bX_i'\bu_i\right] =0 $$ for any fixed value of $T$.  
  
- If the model is dynamic or strict exogeneity fails for any other reason, the mean group estimator will typically only be consistent as both $N, T\to\infty$. In this case it may be that $$ \E\left[ \left(\bX_i'\bX_i \right)^{-1}\bX_i'\bu_i\right] \neq 0 ,$$ and $\hat{\bbeta}_{MG}$ will be biased for any given finite $T$. However, under standard assumptions that limit dependence across $t$, this expectation will typically be of the order $O(T^{-1})$.

 


## Comparing Estimators

We now have have three possible estimation strategies 

|                              | Static case      |                     | Dynamic case with *k* lags |                     |
|------------------------------|------------------|---------------------|----------------------------|---------------------|
|                              | Within           | MG                  | IV                         | MG                  |
| **Data requirements**        | \( T \geq 2 \)  | \( T \geq p \)      | \( T \geq k+2 \)           | \( T \geq p+k \)    |
| **Assumptions on \( (\beta_i, X_i) \)** |  [\tilde{X}_i'\tilde{X}_i\eta_i]=0 \) | None               | No consistency               | None               |
| **Asymptotic framework**     | Fixed-\( T \)   | Fixed-\( T \)       | No consistency             | Large-\( (N, T) \)  |


As a final note on comparison, efficiency . as a consequence of the AM-HM inequality.  possibly [@Pesaran1996, @Pesaran1999, @Hsiao1999]. One can use a Mundlak device to improve effieicnet, see @Breitung2021

 


## Regarding the Rank Condition

